---
title: "doac-ddi"
author: "Kent Hanson"
format: html
editor: visual
---
#To Do
Need to redfine washout periods & grace period
Need to plug in control (pravastatin) somehow


# About

The goal of this analysis is to explore DDI in CVD using the SCCS as a high-throughput screening technique

# Packages

```{r}
#| label: load-packages/functions
#| include: false

pacman::p_load(tidyverse, arrow, duckdb, tictoc, haven, reshape2, lubridate, SCCS, janitor, fs, here, AdhereR, remotes, lme4, gnm, survival, grid, forestploter, duckplyr, xlsx, data.table, progress, readxl, zoo)

# Call functions
source(here("codes/functions.R"))

redbook <- open_dataset("//pharm-psop/Truven Data/Truven Data R/redbook.parquet") |> 
  collect()

```


# Event Data
## CCAE - Identify patients who have the outcome b/n 2009-2021 based on definition by Dhopeshwarkar

Citation: Dhopeshwarkar N, Yang W, Hennessy S, Rhodes JM, Cuker A, Leonard CE. Rate of major bleeding with ibrutinib versus bendamustine-rituximab in chronic lymphocytic leukemia: A population-based cohort study. Am J Hematol. 2022;97(9):E332-E335. doi:10.1002/ajh.26632

```{r}


# Step 1: Filter and collect ccaes cases with transfusion in REVCODE 
ccaes_2009_2021_bleed <- open_dataset("//pharm-psop/Truven Data/Truven Data R/ccae/s") |> 
  select(ENROLID, YEAR, ADMDATE, DISDATE, REVCODE) |> 
  to_duckdb() |> 
  filter(REVCODE %in% c("0390", "0391") & !is.na(ENROLID)) |> #3221885
  mutate(transfusion_code = 1) |> #Create var indicating transfusion code 1. Don't care which code it is
  select(-REVCODE) |> 
  distinct() |> #2297706
  collect() 

#Collect the full inpatient data with relevant variables
ccaei_2009_2021_bleed <- open_dataset("//pharm-psop/Truven Data/Truven Data R/ccae/i", unify_schemas = TRUE) |> 
  select(c(ENROLID, YEAR, ADMDATE, AGE, DAYS, DISDATE, DXVER, PDX, DX1:DX15, PROC1:PROC15)) |> 
  to_duckdb() |> 
  collect() #24224052 obs

#Merge ccaei with ccaes to get REVCODE
ccaei_2009_2021_bleed_merge <- ccaei_2009_2021_bleed |> 
  filter(!is.na(ENROLID)) |>
  left_join(ccaes_2009_2021_bleed, by = c("ENROLID", "YEAR", "ADMDATE", "DISDATE")) |> 
  replace_na(list(DXVER = "9")) |> 
  filter(DXVER != "") |> #removes blanks that probably indicate ambulance services (at this did for 4082398001)
  mutate(DXVER = as.numeric(DXVER)) #24166824 obs

#Identify IDs with event in ccae using criteria outlined by Leonard et al (time: 14 min)
ccae_bleed_outcome_2009_2021 <- ccaei_2009_2021_bleed_merge |> 
  mutate(
    bleed_code = if_else(
      DXVER == 9, 
      if_any(PDX, ~str_detect(.x, {{all_icd9_bleeds_ind}})) |
        (if_any(PDX, ~str_detect(.x, {{all_gib_icd9_possible}})) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}})) |
            !is.na(transfusion_code))) | 
      (if_any(PDX, ~str_detect(.x, {{all_unspec_icd9_possible}})) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}})))) |
      (if_any(PDX, ~ gu_icd9_possible %in% .x)  &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}}))) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_comb_sec}})))),
      if_else(
        DXVER == 0, 
        if_any(PDX, ~str_detect(.x, {{all_icd10_bleeds_ind}})) |
          (if_any(PDX, ~str_detect(.x, {{all_gib_icd10_possible}})) &
             (if_any(DX2:DX15, ~str_detect(.x, {{all_icd10_bleeds_ind}})) |
                !is.na(transfusion_code))) | 
          (if_any(PDX, ~str_detect(.x, {{all_unspec_icd10_possible}})) &
             (if_any(DX2:DX15, ~str_detect(.x, {{all_icd10_bleeds_ind}})))),
        NA
      )
    )
  ) |>
  group_by(ENROLID) |> 
  mutate(bleed_ever = as.integer(any(bleed_code))) |> 
  filter(bleed_ever == 1) |> #803882
  ungroup() #We have to keep this in because it pulls in people who have had a bleed event, but also all other inpt admissions. Need that to determine cases where trauma was experienced day before/after admission date.

ccae_bleed_outcome2 <- ccae_bleed_outcome_2009_2021 |> 
  mutate(
    trauma_code = if_else(
      DXVER == 9,
      if_any(DX1:DX15, ~str_detect(.x, {{trauma_check_icd9}})) |
        if_any(PROC1:PROC15, ~str_detect(.x, {{trauma_hcpcs_all}})), 
      if_else(
        DXVER == 0,
        if_any(DX1:DX15, ~str_detect(.x, {{trauma_check_icd10}})) |
          if_any(PROC1:PROC15, ~str_detect(.x, {{trauma_hcpcs_all}})),
        NA
      )
    )
  ) 

inpatient_trauma <- ccae_bleed_outcome2 |> 
  select(ENROLID, ADMDATE, DXVER, trauma_code) |> 
  filter(trauma_code == TRUE) |> 
  mutate(source = "inpatient") |>  #34762
  select(ENROLID, ADMDATE)

#Above collects patients who had an inpatient bleed event. Need to pull them into outpatient dataset to search for trauma
outcome_enrolid <- unique(ccae_bleed_outcome_2009_2021$ENROLID)

ccaeo_2009_2021_bleed <- open_dataset("//pharm-psop/Truven Data/Truven Data R/ccae/o", unify_schemas = TRUE) |> 
  select(ENROLID, SVCDATE, DXVER, DX1, DX2, DX3, DX4, PROC1) |> 
  to_duckdb() |> 
  filter(ENROLID %in% outcome_enrolid) |> 
  collect() #97565595 obs

ccaeo_2009_2021_bleed2 <- ccaeo_2009_2021_bleed |> 
  replace_na(list(DXVER = "9")) |> 
  filter(DXVER != "") |> #removes blanks that probably indicate ambulance services (at this did for 4082398001)
  mutate(DXVER = as.numeric(DXVER)) |> 
  mutate(trauma_code = if_else(
      DXVER == 9,
      if_any(DX1:DX4, ~str_detect(.x, {{trauma_check_icd9}})) |
        if_any(PROC1, ~str_detect(.x, {{trauma_hcpcs_all}})), 
      if_else(
        DXVER == 0,
        if_any(DX1:DX4, ~str_detect(.x, {{trauma_check_icd10}})) |
          if_any(PROC1, ~str_detect(.x, {{trauma_hcpcs_all}})),
        NA
      )
    )
  ) #97467343 obs

# Outpatient trauma codes
outpatient_trauma <- ccaeo_2009_2021_bleed2 |> 
  select(ENROLID, SVCDATE, DXVER, trauma_code) |> 
  filter(trauma_code == TRUE) |> 
  mutate(ADMDATE = SVCDATE, source = "outpatient") |> 
  select(ENROLID, ADMDATE) #786154 obs
  
# Combine trauma codes
all_trauma_codes <- bind_rows(inpatient_trauma, outpatient_trauma) |> 
  distinct() |> 
  arrange(ENROLID, ADMDATE) |>  #238530 obs
  rename(trauma_date = ADMDATE)

#Join trauma codes with main dataset; identify exclusion events (i.e., those with trauma 1d before through 1d post ADMDATE)
ccae_bleed_outcome_merged <- ccae_bleed_outcome_2009_2021 |> 
  left_join(all_trauma_codes, by = "ENROLID") |> 
   mutate(
    within_window = (ADMDATE - 1 <= trauma_date & trauma_date <= ADMDATE + 1)
  ) |> # 2087406 obs
  filter(within_window) |> # 42386 obs
  distinct(ENROLID, ADMDATE) |> # 39010 obs
  mutate(exclusion_event = 1) 


#Join the dataset back to original dataset and then filter out exclusion events
ccae_bleed_outcome_no_trauma <- ccae_bleed_outcome_2009_2021 |> 
  left_join(ccae_bleed_outcome_merged, by = c("ENROLID", "ADMDATE")) |> 
  filter(bleed_code == TRUE) |> #305038 obs
  filter(is.na(exclusion_event)) #294423 obs


#Save dataset so don't have to do that again. Need to re-save in correct folder before uploading to github
ccae_bleed_outcome_no_trauma |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ccae_bleed_outcome_no_trauma.parquet")

#Open dataset
ccae_bleed_outcome_no_trauma <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ccae_bleed_outcome_no_trauma.parquet")
```

## MDCR
```{r}
##MDCR - 8 min to run entire mdcr inpt

# Step 1: Filter and collect mdcrs cases with transfusion in REVCODE 
mdcrs_2009_2021_bleed <- open_dataset("//pharm-psop/Truven Data/Truven Data R/mdcr/s") |> 
  select(ENROLID, YEAR, ADMDATE, DISDATE, REVCODE) |> 
  to_duckdb() |> 
  filter(REVCODE %in% c("0390", "0391") & !is.na(ENROLID)) |> 
  mutate(transfusion_code = 1) |> 
  select(-REVCODE) |> 
  distinct() |> 
  collect() # 950470 obs

#Collect the full inpatient data with relevant variables
mdcri_2009_2021_bleed <- open_dataset("//pharm-psop/Truven Data/Truven Data R/mdcr/i", unify_schemas = TRUE) |> 
  select(c(ENROLID, YEAR, ADMDATE, AGE, DAYS, DISDATE, DXVER, PDX, DX1:DX15, PROC1:PROC15)) |> 
  to_duckdb() |> 
  collect() # 7293408 obs

#Merge mdcri with mdcrs to get REVCODE
mdcri_2009_2021_bleed_merge <- mdcri_2009_2021_bleed |> 
  filter(!is.na(ENROLID)) |>
  left_join(mdcrs_2009_2021_bleed, by = c("ENROLID", "YEAR", "ADMDATE", "DISDATE")) |> 
  replace_na(list(DXVER = "9")) |> 
  filter(DXVER != "") |>
  mutate(DXVER = as.numeric(DXVER)) #7292396 obs

#Identify IDs with event in mdcr using criteria outlined by Leonard et al (time: 14 min)
mdcr_bleed_outcome_2009_2021 <- mdcri_2009_2021_bleed_merge |> 
  mutate(
    bleed_code = if_else(
      DXVER == 9, 
      if_any(PDX, ~str_detect(.x, {{all_icd9_bleeds_ind}})) |
        (if_any(PDX, ~str_detect(.x, {{all_gib_icd9_possible}})) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}})) |
            !is.na(transfusion_code))) | 
      (if_any(PDX, ~str_detect(.x, {{all_unspec_icd9_possible}})) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}})))) |
      (if_any(PDX, ~ gu_icd9_possible %in% .x)  &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}}))) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_comb_sec}})))),
      if_else(
        DXVER == 0, 
        if_any(PDX, ~str_detect(.x, {{all_icd10_bleeds_ind}})) |
          (if_any(PDX, ~str_detect(.x, {{all_gib_icd10_possible}})) &
             (if_any(DX2:DX15, ~str_detect(.x, {{all_icd10_bleeds_ind}})) |
                !is.na(transfusion_code))) | 
          (if_any(PDX, ~str_detect(.x, {{all_unspec_icd10_possible}})) &
             (if_any(DX2:DX15, ~str_detect(.x, {{all_icd10_bleeds_ind}})))),
        NA
      )
    )
  ) |>
  group_by(ENROLID) |> 
  mutate(bleed_ever = as.integer(any(bleed_code))) |> 
  filter(bleed_ever == 1) |> #832236
  ungroup() 

mdcr_bleed_outcome2 <- mdcr_bleed_outcome_2009_2021 |> 
  mutate(
    trauma_code = if_else(
      DXVER == 9,
      if_any(DX1:DX15, ~str_detect(.x, {{trauma_check_icd9}})) |
        if_any(PROC1:PROC15, ~str_detect(.x, {{trauma_hcpcs_all}})), 
      if_else(
        DXVER == 0,
        if_any(DX1:DX15, ~str_detect(.x, {{trauma_check_icd10}})) |
          if_any(PROC1:PROC15, ~str_detect(.x, {{trauma_hcpcs_all}})),
        NA
      )
    )
  ) 

inpatient_trauma <- mdcr_bleed_outcome2 |> 
  select(ENROLID, ADMDATE, DXVER, trauma_code) |> 
  filter(trauma_code == TRUE) |> 
  mutate(source = "inpatient") |>  #52716
  select(ENROLID, ADMDATE)

#Above collects patients who had an inpatient bleed event. Need to pull them into outpatient dataset to search for trauma
outcome_enrolid <- unique(mdcr_bleed_outcome_2009_2021$ENROLID)

mdcro_2009_2021_bleed <- open_dataset("//pharm-psop/Truven Data/Truven Data R/mdcr/o", unify_schemas = TRUE) |> 
  select(ENROLID, SVCDATE, DXVER, DX1, DX2, DX3, DX4, PROC1) |> 
  to_duckdb() |> 
  filter(ENROLID %in% outcome_enrolid) |> 
  collect() #116544259 obs

mdcro_2009_2021_bleed2 <- mdcro_2009_2021_bleed |> 
  replace_na(list(DXVER = "9")) |> 
  filter(DXVER != "") |> 
  mutate(DXVER = as.numeric(DXVER)) |> 
  mutate(trauma_code = if_else(
      DXVER == 9,
      if_any(DX1:DX4, ~str_detect(.x, {{trauma_check_icd9}})) |
        if_any(PROC1, ~str_detect(.x, {{trauma_hcpcs_all}})), 
      if_else(
        DXVER == 0,
        if_any(DX1:DX4, ~str_detect(.x, {{trauma_check_icd10}})) |
          if_any(PROC1, ~str_detect(.x, {{trauma_hcpcs_all}})),
        NA
      )
    )
  ) #116473799 obs

# Outpatient trauma codes
outpatient_trauma <- mdcro_2009_2021_bleed2 |> 
  select(ENROLID, SVCDATE, DXVER, trauma_code) |> 
  filter(trauma_code == TRUE) |> 
  mutate(ADMDATE = SVCDATE, source = "outpatient") |> 
  select(ENROLID, ADMDATE) #1538790 obs
  
# Combine trauma codes
all_trauma_codes <- bind_rows(inpatient_trauma, outpatient_trauma) |> 
  distinct() |> 
  arrange(ENROLID, ADMDATE) |>  #526314 obs
  rename(trauma_date = ADMDATE)

#Join trauma codes with main dataset; identify exclusion events (i.e., those with trauma 1d before through 1d post ADMDATE)
mdcr_bleed_outcome_merged <- mdcr_bleed_outcome_2009_2021 |> 
  left_join(all_trauma_codes, by = "ENROLID") |> 
   mutate(
    within_window = (ADMDATE - 1 <= trauma_date & trauma_date <= ADMDATE + 1)
  ) |> # 2087406 obs
  filter(within_window) |> 
  distinct(ENROLID, ADMDATE) |> # 58526 obs
  mutate(exclusion_event = 1) 


#Join the dataset back to original dataset and then filter out exclusion events
mdcr_bleed_outcome_no_trauma <- mdcr_bleed_outcome_2009_2021 |> 
  left_join(mdcr_bleed_outcome_merged, by = c("ENROLID", "ADMDATE")) |> 
  filter(bleed_code == TRUE) |> 
  filter(is.na(exclusion_event)) #278667 obs


#Save dataset so don't have to do that again. Need to re-save in correct folder before uploading to github
mdcr_bleed_outcome_no_trauma |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/mdcr_bleed_outcome_no_trauma.parquet")

#Open dataset
mdcr_bleed_outcome_no_trauma <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/mdcr_bleed_outcome_no_trauma.parquet")
```

## MDCR + CCAE
```{r}
#Merge inpatient files
all_outcome <- bind_rows(ccae_bleed_outcome_no_trauma, mdcr_bleed_outcome_no_trauma) |> 
  arrange(ENROLID, ADMDATE) |> 
  group_by(ENROLID) |> 
  mutate(hospnum = row_number()) |> 
  ungroup() |> 
  mutate(eventnum= row_number()) |> 
  select(c(ENROLID, ADMDATE, DAYS, DISDATE, hospnum, eventnum)) #1297106 obs; 1579503 post adjustment; 570608 post second adjustment


all_outcome |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_inpatient_bleed_no_trauma.parquet")

all_inpatient_bleed_no_trauma <-  read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_inpatient_bleed_no_trauma.parquet")

#Create vector that includes ENROLID of all individuals who experienced outcome in 2009-2021
#outcome_vec <- all_inpatient_bleed_no_trauma$ENROLID #1297106

#Shouldn't this be distinct obs? 
outcome_vec <- unique(all_inpatient_bleed_no_trauma$ENROLID) #499061

```




```{r}
#| label: Drug Data
#| echo: false

#Create cohort of patients who had event in either ccae or mdcr and also filled a statin.
ccaed_2009_2021 <- open_dataset(("//pharm-psop/Truven Data/Truven Data R/ccae/d")) |> 
  to_duckdb() |> 
  select(c(ENROLID, NDCNUM, SVCDATE, YEAR, AGE, SEX, DAYSUPP))|>
  filter(ENROLID %in% outcome_vec) |> 
  distinct() |> 
  collect() |> 
  left_join(redbook, by = "NDCNUM") |>  
  mutate(dataset = "ccae") |> 
  select(c(ENROLID, NDCNUM, SVCDATE, YEAR, AGE, SEX, DAYSUPP, THRDTDS, GENNME, MASTFRM, dataset))   #32122633

#Save dataset so don't have to do that again. Need to re-save in correct folder before uploading to github
ccaed_2009_2021 |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ccaed_2009_2021.parquet")

#Open dataset
ccaed_2009_2021 <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ccaed_2009_2021.parquet")
  
#Repeat for MDCR Cohort & merge with ccaed
mdcrd_2009_2021 <- open_dataset(("//pharm-psop/Truven Data/Truven Data R/mdcr/d")) |> 
  to_duckdb() |> 
  select(c(ENROLID, NDCNUM, SVCDATE, YEAR, AGE, SEX, DAYSUPP))|>
  filter(ENROLID %in% outcome_vec) |> 
  distinct() |> 
  collect () |> 
  left_join(redbook, by = "NDCNUM") |> 
  mutate(dataset = "mdcr") |> 
  select(c(ENROLID, NDCNUM, SVCDATE, YEAR, AGE, SEX, DAYSUPP, THRDTDS, GENNME, MASTFRM, dataset)) #45127650

#Save dataset so don't have to do that again. Need to re-save in correct folder before uploading to github
mdcrd_2009_2021 |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/mdcrd_2009_2021.parquet")

#Open dataset
mdcrd_2009_2021 <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/mdcrd_2009_2021.parquet")
  

#Bind drug files
all_drug <- rbind(ccaed_2009_2021, mdcrd_2009_2021) #77250283

#Save dataset so don't have to do that again. Need to re-save in correct folder before uploading to github
all_drug |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_drug_2009_2021.parquet")

#Open dataset
all_drug_2009_2021 <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_drug_2009_2021.parquet")







```


# Assign index date

```{r}
##Flag Object drugs and assign index date
oac_drug_data <- all_drug_2009_2021 |> 
  arrange(ENROLID, SVCDATE) |>
  filter(!is.na(AGE)) |> 
  mutate(oac_flag = if_any(GENNME,~ str_detect(.x, paste(object_oac, collapse = "|")))) |> 
  filter(oac_flag ==TRUE) |> #1830509
  group_by(ENROLID) |> 
  mutate(index_date = min(SVCDATE)) |> 
  filter(index_date > '2009-07-02') |> #Ensures first fill after 12/31 so no prior oac use within 1 year
  ungroup() |> 
  mutate(
    GENNME = if_else(GENNME == "Rivaroxaban;Rivaroxaban", "Rivaroxaban", GENNME),
    index_med = if_else(index_date == SVCDATE, GENNME, NA)) |> #create var for index med
  group_by(ENROLID) |> 
  fill(index_med, .direction = "down") |> #fill down for rest of obs
  ungroup() |> 
  mutate(doac_switch = if_else(GENNME == index_med, "match", "switch")) |> 
  # Create a flag column for claims with negative days' supply
  mutate(negative_days_flag = DAYSUPP < 0, 
         cancel_flag = FALSE,
         days_to_closest_positive_claim = NA) #1134349

```


# Clean object drug (oac) data (i.e., negative / duplicate fills)
```{r}
# Identify pairs of positive and negative claims
for (i in seq_len(nrow(oac_drug_data))) { ## XXXX FlAG
  if (oac_drug_data$negative_days_flag[i]) {
    # Get the current enrollee ID and service date for the negative claim
    enrolid <- oac_drug_data$ENROLID[i]
    svcdate <- oac_drug_data$SVCDATE[i]
    daysupp_negative <- oac_drug_data$DAYSUPP[i]
    
    # Check for positive claims on the same day or within 15 days prior
    positive_claims_15 <- oac_drug_data |>
      filter(ENROLID == enrolid,
             SVCDATE <= svcdate,
             SVCDATE >= (svcdate - days(15)),
             DAYSUPP > 0)
    
    # Check for exact match positive claims within 60 days prior
    exact_match_60 <- oac_drug_data |>
      filter(ENROLID == enrolid,
             SVCDATE <= svcdate,
             SVCDATE >= (svcdate - days(60)),
             DAYSUPP == abs(daysupp_negative))
    
    # If there are positive claims within 15 days, find the closest one
    if (nrow(positive_claims_15) > 0) {
      closest_positive_claim <- positive_claims_15 |>
        arrange(desc(SVCDATE)) |>
        slice(1)
      
      days_diff <- as.numeric(difftime(svcdate, closest_positive_claim$SVCDATE, units = "days"))
      oac_drug_data$days_to_closest_positive_claim[i] <- days_diff
      
      # Set the cancel flag for both the negative and positive claims
      oac_drug_data$cancel_flag[i] <- TRUE
      oac_drug_data$cancel_flag[which(oac_drug_data$ENROLID == enrolid & 
                             oac_drug_data$SVCDATE == closest_positive_claim$SVCDATE & 
                             oac_drug_data$DAYSUPP == closest_positive_claim$DAYSUPP)] <- TRUE
    }
    
    # If there are exact match positive claims within 60 days, find the closest one
    if (nrow(exact_match_60) > 0) {
      closest_positive_claim <- exact_match_60 |>
        arrange(desc(SVCDATE)) |>
        slice(1)
      
      # Set the cancel flag for both the negative and positive claims
      oac_drug_data$cancel_flag[i] <- TRUE
      oac_drug_data$cancel_flag[which(oac_drug_data$ENROLID == enrolid & 
                             oac_drug_data$SVCDATE == closest_positive_claim$SVCDATE & 
                             oac_drug_data$DAYSUPP == closest_positive_claim$DAYSUPP)] <- TRUE
    }
  }
}

# Remove cancelled claims
oac_drug_data_uncancelled <- oac_drug_data |>
  filter(!cancel_flag & !negative_days_flag)

#Select max value if multiple fills on same day. 
oac_drug_data_filtered <- oac_drug_data_uncancelled |>
  group_by(ENROLID, SVCDATE) |>
  mutate(fill_count = n()) |>
  ungroup() |>
  filter(!(fill_count > 1 & DAYSUPP != max(DAYSUPP, na.rm = TRUE))) |> 
  select(-fill_count)

# Filter for initial low days' supply
oac_drug_data_min_index <- oac_drug_data_filtered|>
  arrange(ENROLID, SVCDATE, DAYSUPP) |> 
  group_by(ENROLID) |>
  mutate(first_fill_date = min(SVCDATE)) |>
  ungroup() |> 
  mutate(init_ds_low = if_else(SVCDATE == first_fill_date & DAYSUPP <7, "remove", NA)) |> 
  group_by(ENROLID) |> 
  fill(init_ds_low, .direction = "down") |> 
  ungroup() |> 
  filter(is.na(init_ds_low))

# Filter based on switch date
oac_drug_data_switch <- oac_drug_data_min_index |> 
 group_by(ENROLID) |>
  mutate(first_switch_date = ifelse(any(doac_switch == "switch"), min(SVCDATE[doac_switch == "switch"], na.rm = TRUE), NA)) |> 
  ungroup() |>
  filter(is.na(first_switch_date) | SVCDATE < first_switch_date)

```


# Continuous drug exposure rules application
```{r}
##Apply continuous exposure rules
oac_drug_data_continuous <- oac_drug_data_switch |> 
  mutate(obj_fill_end = SVCDATE + DAYSUPP ) |>  #7d grace (Zhou 2020); assuming 80% adherence here; removed + (DAYSUPP *0.2) based on recent paper by leonard on grace periods
  group_by(ENROLID) |> 
  mutate(obj_end_lagged = lag(obj_fill_end)) |> 
  ungroup() |> 
  mutate(
    cont_expo1 = ifelse(SVCDATE <= obj_end_lagged, "Continuous", "New" ),  #Flag if next fill falls outside grace period
    cont_expo2 = ifelse(is.na(cont_expo1), "New", cont_expo1),  #Change first fill values (currently NA) to "New"
    censor = ifelse(cont_expo1=="New" & cont_expo2 == "New", 1, NA)) |>   #Filter if "New", "New". Should only occur if new start that isnt first fill
  group_by(ENROLID) |> 
  fill(censor)  |>  #Fills down the censored variables for filtering; 243201
  ungroup() |> 
  filter(is.na(censor)) #148709

##Create cohort of oac users
cohort_oac_users <- oac_drug_data_continuous |> 
  group_by(ENROLID) |> 
  mutate(obj_period_end = max(obj_fill_end)) |> 
  ungroup() |> 
  select(ENROLID, GENNME, AGE, SEX, index_date, obj_period_end) |> 
  distinct(ENROLID, .keep_all = TRUE) #41800

```

## Continuous enrollment (183 days pre-index)

```{r}
#Write parquet file for patients 18+ with index date and ENROLID for CE assessment
cohort_oac_users |>
  arrange(ENROLID, index_date) |> 
  filter(AGE>=18) |>  #41975
  select(ENROLID, index_date) |> 
  write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ids_with_indexdate.parquet")

#Read in dataset with ENROLID & index_date
cohort_ids_for_CE <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ids_with_indexdate.parquet")

cont_enrollment_ids <- unique(cohort_ids_for_CE$ENROLID)

#Open relevant T files for CE scanning; filter for specific ids
ccae_enroll <- open_dataset("//pharm-psop/Truven Data/Truven Data R/ccae/t") |> 
  select(ENROLID, DTSTART, DTEND) |> 
  to_duckdb() |> 
  filter(ENROLID %in% cont_enrollment_ids) |> 
  collect()

mdcr_enroll <- open_dataset("//pharm-psop/Truven Data/Truven Data R/mdcr/t") |> 
  select(ENROLID, DTSTART, DTEND) |> 
  to_duckdb() |> 
  filter(ENROLID %in% cont_enrollment_ids) |> 
  collect()

all_enroll <- rbind(ccae_enroll, mdcr_enroll)

#Create parquet file of T datasets with relevant IDs
all_enroll |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/enrollment_parquet.parquet") 
enrollment_parquet <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/enrollment_parquet.parquet") #Read in parquet

continuous_enrollment_result <- ContinuousEnrollment(
    enrollment_data = enrollment_parquet,
    data = cohort_ids_for_CE,
    days_after = 0,
    days_before = 183,
    max_gap = 0,
    index_date_var = index_date
) #47837 obs 

#Save ids with ce as vector
ids_with_ce <- continuous_enrollment_result$ENROLID


```

#Chunk to evaluate stop of follow-up (disenrollment)
```{r}
#Filter out patients who do not meet cont_enroll_req criteria
cohort_oac_users_with_ce <- cohort_oac_users |>  
  filter(ENROLID %in% ids_with_ce)

# Calculate gaps using lag on EndDate
disenrollment_data <- all_enroll |> 
  select(ENROLID, DTSTART, DTEND) |> 
  arrange(ENROLID, DTSTART) |> 
  group_by(ENROLID) |> 
  mutate(
    PreviousEndDate = lag(DTEND),
    GapDays = as.integer(DTSTART - PreviousEndDate)) |>  # Get prior DTEND and calculate gap between DTSTART
  ungroup() |> 
  left_join(cohort_oac_users_with_ce, by = "ENROLID") |> #Join with dataset w/ observation start time
  group_by(ENROLID) |> 
  mutate(flag = if_else(DTSTART < index_date - 30, 1, 0)) |> #Creates flag to identify if DTSTART is 30 days before index. If so its assigned value of 1
  filter(flag == 0) |> # filters those patients out
  mutate(
    censor_dt = if_else(GapDays > 30 & PreviousEndDate > index_date, 1, 0),  #Creates censoring variable gap >30d & prior end date is after index
    censor_dt = cummax(censor_dt) # Propagate the censor flag to all subsequent rows
  ) |> 
  filter(censor_dt == 0) |> 
  mutate(lost_ce_dt = max(DTEND)) |> #Use max date populate all rows with day of disenrollment
  ungroup() |> 
  distinct(ENROLID, index_date, obj_period_end, lost_ce_dt) |> 
  mutate(new_obj_period_end = pmin(lost_ce_dt, obj_period_end, na.rm = TRUE)) |> 
  select(ENROLID, new_obj_period_end)

#Join back with dataset and update obj_period_end variable
cohort_oac_users_with_ce_update <- cohort_oac_users |> 
  filter(ENROLID %in% ids_with_ce) |> 
  left_join(disenrollment_data, by = "ENROLID") |> 
  select(-obj_period_end) |> 
  rename(obj_period_end = new_obj_period_end)

```



# Develop table 1
```{r}

##Left join object data to outcome data to duplicate person for each hosp (e.g., 1 pt w/ 3 hosp who filled 5 meds = 15 obs)
analytic_cohort_oac <- left_join(cohort_oac_users_with_ce_update, all_inpatient_bleed_no_trauma, by = "ENROLID") |> 
  arrange(ENROLID, hospnum, ADMDATE) |> 
  mutate(day_obs_start = 0) |> 
  mutate(day_obs_end = obj_period_end - index_date) |> 
  mutate(day_of_event = ADMDATE - index_date) |> 
  mutate(event_occur_outside_obs = ADMDATE < index_date | ADMDATE > obj_period_end) |> 
  filter(event_occur_outside_obs==FALSE) |>  #17103 (all doac); 5767 obs
  mutate(object = GENNME) |> 
  select(c(-GENNME, -event_occur_outside_obs)) |> 
  mutate(age_group = case_when(
    AGE >= 18 & AGE <= 44 ~ "18-44",
    AGE >= 45 & AGE <= 64 ~ "45-64",
    AGE >= 65 & AGE <= 74 ~ "65-74",
    AGE >= 75 & AGE <= 84 ~ "75-84",
    AGE >= 85 & AGE <= 90 ~ "85-90",
    AGE > 90 ~ ">90",
    TRUE ~ "Other"
  ))

# Calculate unique person-days
person_days_data <- analytic_cohort_oac %>%
  select(ENROLID, object, day_obs_start, day_obs_end) %>%
  distinct() %>%
  group_by(object, ENROLID) %>%
  summarise(total_person_days = sum(day_obs_end - day_obs_start, na.rm = TRUE), .groups = 'drop')

# Calculate the proximity of the event to the end of follow-up
proximity_obs_end_summary <- analytic_cohort_oac %>%
  mutate(proximity_to_end = as.numeric(day_obs_end - day_of_event)) |> 
  group_by(object) %>%
  summarise(
    mean_proximity_end = mean(proximity_to_end, na.rm = TRUE),
    sd_proximity_end = sd(proximity_to_end, na.rm = TRUE),
    .groups = 'drop'
  )

# Calculate the proximity of the event to the end of follow-up
proximity_obs_st_summary <- analytic_cohort_oac %>%
  mutate(proximity_to_st = as.numeric(day_of_event - day_obs_start)) |> 
  group_by(object) %>%
  summarise(
    mean_proximity_st = mean(proximity_to_st, na.rm = TRUE),
    sd_proximity_st = sd(proximity_to_st, na.rm = TRUE),
    .groups = 'drop'
  )

# Summarize other statistics
summary_table <- analytic_cohort_oac %>%
  group_by(object) %>%
  summarise(
    number_of_cases = n_distinct(ENROLID),
    number_of_events = n(),
    n_female = sum(SEX == 2),
    perc_female = mean(SEX == 2) * 100,
    mean_age = mean(AGE, na.rm = TRUE),
    sd_age = sd(AGE, na.rm = TRUE),
    age_18_44 = sum(age_group == "18-44"),
    age_45_64 = sum(age_group == "45-64"),
    age_65_74 = sum(age_group == "65-74"),
    age_75_84 = sum(age_group == "75-84"),
    age_85_90 = sum(age_group == "85-90"),
    .groups = 'drop'
  )

# Combine the person-days data and proximity summary with the summary statistics
summary_table <- summary_table %>%
  left_join(person_days_data %>%
              group_by(object) %>%
              summarise(person_days = sum(total_person_days, na.rm = TRUE), .groups = 'drop'),
            by = "object") %>%
  left_join(proximity_obs_end_summary, by = "object") %>%
  left_join(proximity_obs_st_summary, by = "object") |> 
  mutate(
    n_perc_female = paste0(n_female, " (", round(perc_female, 2), "%)"),
    mean_sd_age = paste0(round(mean_age, 2), " (", round(sd_age, 2), ")"),
    mean_sd_proximity_st = paste0(round(mean_proximity_st, 2), " (", round(sd_proximity_st, 2), ")"),
    mean_sd_proximity_end = paste0(round(mean_proximity_end, 2), " (", round(sd_proximity_end, 2), ")"),
  ) %>%
  select(
    object, number_of_cases, person_days, number_of_events,
    n_perc_female, mean_sd_age, age_18_44, age_45_64,
    age_65_74, age_75_84, age_85_90, mean_sd_proximity_st, mean_sd_proximity_end
  )
```


# Study-specific criteria

```{r}
##TRY THIS MEGA LOOP
# Initialize the final results table
final_results_table <- data.frame()

# Loop over each OAC
for (oac in object_oac) {
  cat("Processing OAC:", oac, "\n")

##Left join object data to outcome data to duplicate person for each hosp (e.g., 1 pt w/ 3 hosp who filled 5 meds = 15 obs)
analytic_cohort_oac <- left_join(cohort_oac_users_with_ce_update, all_inpatient_bleed_no_trauma, by = "ENROLID") |> 
  arrange(ENROLID, hospnum, ADMDATE) |> 
  mutate(day_obs_start = 0) |> 
  mutate(day_obs_end = obj_period_end - index_date) |> 
  mutate(day_of_event = ADMDATE - index_date) |> 
  mutate(event_occur_outside_obs = ADMDATE < index_date | ADMDATE > obj_period_end) |> 
  filter(event_occur_outside_obs==FALSE) |>  #17103 (all doac); 5767 obs
  filter(GENNME == "Apixaban") |> #Toggle for loop. change to oac to run
  mutate(object = GENNME) |> 
  select(c(-GENNME, -event_occur_outside_obs)) #7342 apix; 1943 apix; 1790 rivaroxaban; 1518 apixaban

ids_for_loop <- unique(analytic_cohort_oac$ENROLID)

dataset_for_loop <- analytic_cohort_oac |> 
  arrange(ENROLID, ADMDATE) |> 
  distinct(ENROLID, .keep_all = TRUE) |> 
  select(ENROLID, index_date, obj_period_end, day_obs_start, day_obs_end, object)

dataset_for_loop_outcome <- analytic_cohort_oac |> 
  arrange(ENROLID, ADMDATE) |> 
  select(ENROLID, day_of_event) |> 
  distinct() |> #10 duplicates (i.e., multiple events same day)
  group_by(ENROLID) |>
  mutate(event_number = row_number()) |>
  ungroup() |> 
  pivot_wider(
    id_cols = ENROLID, 
    names_from = event_number, 
    values_from = day_of_event,
    names_prefix = "event_"
  )


#Precipitant List Generation


#Create a list of precipitant drugs that are filled during the object window for each person

#Step 1: Isolate ENROLIDs and retain index date and stop date (i.e., obj period end)
precipitant_cohort <- analytic_cohort_oac |> 
  arrange(ENROLID, ADMDATE) |> 
  distinct(ENROLID, .keep_all = TRUE) |>  
  select(ENROLID, object, index_date, obj_period_end)

#Join ENROLID with entire drug data file to pull in Rx history. Filter for drugs used in obj_wind
precipitant_cohort_2 <- left_join(precipitant_cohort, all_drug_2009_2021, by = "ENROLID") |> #595155
  arrange(ENROLID, SVCDATE) |> 
  mutate(precip_start = SVCDATE) |> 
  mutate(precip_end = SVCDATE + DAYSUPP) |> 
  mutate(
    concom = if_else(
      (precip_start <= obj_period_end & precip_end >= index_date), 1, 0
    )) |> 
  filter(concom ==1) |> 
  mutate(doac = if_any(GENNME,~ str_detect(.x, paste(object_oac, collapse = "|")))) |> 
  filter(doac ==FALSE) |> 
  select(-doac) 

#Filter out the drugs from the exclusion list plus a few additional outliers
precipitant_cohort_3 <- precipitant_cohort_2|> 
  filter(!MASTFRM %in% excluded_mastfrm) |>
  filter(!THRDTDS %in% excluded_thrdtds) |> 
  filter(!str_detect(THRDTDS, "S/M")) |> 
  filter(!GENNME %in% excluded_gennme)

#Pull out the individual drugs. Split out combination products
precipitant_active_ingredients <- precipitant_cohort_3 |> 
  separate(GENNME, into = paste0("col", 1:10), sep = "/", fill = "right") |> 
  pivot_longer(cols = starts_with("col"), names_to = "name", values_to = "GENNME", values_drop_na = TRUE, names_repair = "unique") |> 
  separate(GENNME, into = paste0("drug", 1:10), sep = ";", fill = "right") |> 
  pivot_longer(cols = starts_with("drug"), names_to = "name2", values_to = "GENNME", values_drop_na = TRUE, names_repair = "unique") |> 
  filter(!is.na(GENNME)) |> 
  select(ENROLID, GENNME)


# Write the precipitants dataframe to an Excel file to allow manual renaming for mismatches
#write.xlsx(precipitant_active_ingredient, file = "precipitant_active_ingredient.xlsx")

# Created a mapping pathway for drugs used with ANY OAC. Read in here
drug_mapping <- read_excel("drug_mapping.xlsx")

#First use the mapping to correct names in the drug list 
precipitant_active_ingredient_mapped <- precipitant_active_ingredients |> 
  left_join(drug_mapping, by = "GENNME") |> 
  mutate(GENNME = if_else(is.na(NEWNAME), GENNME, NEWNAME)) |> 
  select(-NEWNAME)

# Count unique ENROLID for each drug and limit drug list to those used among 5+ unique people
drug_counts <- precipitant_active_ingredient_mapped %>%
  group_by(GENNME) %>%
  summarise(unique_enrolid_count = n_distinct(ENROLID)) |> 
  filter(unique_enrolid_count > 4)

# Save as a vector for future use in a loop
precipitant_vector <- unique(drug_counts$GENNME)

#Next use the mapping to correct names in the precipitant dataset. 
##First derive function
replace_drug_names_in_string <- function(drug_string, mapping) {
  for (i in 1:nrow(mapping)) {
    drug_string <- gsub(mapping$GENNME[i], mapping$NEWNAME[i], drug_string, fixed = TRUE)
  }
  return(drug_string)
}

# Apply the function to the GENNME column in the main dataset
precipitant_cohort_4 <- precipitant_cohort_3 %>%
  arrange(ENROLID, SVCDATE) |>
  filter(!is.na(AGE)) |> 
  filter(ENROLID %in% ids_for_loop) |> 
  mutate(GENNME = sapply(GENNME, replace_drug_names_in_string, mapping = drug_mapping))

# Modify cohort so have appropriate variable names for later
precipitant_cohort_5 <- precipitant_cohort_4 |> 
  mutate(pre_fill_end = SVCDATE + DAYSUPP + (DAYSUPP *0.2)) |>  
  rename(expo_start_date = SVCDATE) |> 
  rename(expo_end_date = pre_fill_end) |> 
  rename(precipitant=GENNME)




#Apply days' supply cleaning to precipitants


precipitant_cohort_6 <- precipitant_cohort_5 |> 
  group_by(ENROLID, precipitant) %>%
  arrange(expo_start_date) %>%
  mutate(negative_days_flag = DAYSUPP < 0, 
         cancel_flag = FALSE,
         days_to_closest_positive_claim = NA)

# Identify pairs of positive and negative claims
# Define a function to process each group
process_group <- function(df) {
  for (i in seq_len(nrow(df))) {
    if (df$negative_days_flag[i]) {
      # Get the current service date and days supply for the negative claim
      svcdate <- df$expo_start_date[i]
      daysupp_negative <- df$DAYSUPP[i]
      
      # Check for positive claims on the same day or within 15 days prior
      positive_claims_15 <- df %>%
        filter(
          expo_start_date <= svcdate,
          expo_start_date >= (svcdate - days(15)),
          DAYSUPP > 0
        )
      
      # Check for exact match positive claims within 60 days prior
      exact_match_60 <- df %>%
        filter(
          expo_start_date <= svcdate,
          expo_start_date >= (svcdate - days(60)),
          DAYSUPP == abs(daysupp_negative)
        )
      
      # If there are positive claims within 15 days, find the closest one
      if (nrow(positive_claims_15) > 0) {
        closest_positive_claim <- positive_claims_15 %>%
          arrange(desc(expo_start_date)) %>%
          slice(1)
        
        days_diff <- as.numeric(difftime(svcdate, closest_positive_claim$expo_start_date, units = "days"))
        df$days_to_closest_positive_claim[i] <- days_diff
        
        # Set the cancel flag for both the negative and positive claims
        df$cancel_flag[i] <- TRUE
        df$cancel_flag[df$expo_start_date == closest_positive_claim$expo_start_date &
                       df$DAYSUPP == closest_positive_claim$DAYSUPP] <- TRUE
      }
      
      # If there are exact match positive claims within 60 days, find the closest one
      if (nrow(exact_match_60) > 0) {
        closest_positive_claim <- exact_match_60 %>%
          arrange(desc(expo_start_date)) %>%
          slice(1)
        
        # Set the cancel flag for both the negative and positive claims
        df$cancel_flag[i] <- TRUE
        df$cancel_flag[df$expo_start_date == closest_positive_claim$expo_start_date &
                       df$DAYSUPP == closest_positive_claim$DAYSUPP] <- TRUE
      }
    }
  }
  return(df)
}

# Apply the function to each group
precipitant_cohort_7 <- precipitant_cohort_6 %>%
  group_by(ENROLID, precipitant) %>%
  group_modify(~ process_group(.x)) %>%
  ungroup()

# Remove cancelled claims
precipitant_cohort_8 <- precipitant_cohort_7 |>
  filter(!cancel_flag & !negative_days_flag)


# Precipitant loop






##Creates days of exposure start and end, but it creates problems when there are negative ds
precipitant_cohort_9 <- precipitant_cohort_8 |> 
  select(ENROLID, precipitant, expo_start_date, expo_end_date) |> 
  left_join(dataset_for_loop, by = "ENROLID") |> 
  select(ENROLID, object, day_obs_start, day_obs_end, index_date, obj_period_end, precipitant, expo_start_date, expo_end_date) |> 
  mutate(day_exposure_start = as.numeric(expo_start_date - index_date)) |> 
  filter(day_exposure_start <= day_obs_end) |> 
  mutate(day_exposure_end = as.numeric(expo_end_date - index_date)) |> 
  filter(day_exposure_end >= 0)

# Function to merge overlapping intervals
merge_intervals <- function(data) {
  data <- data[order(data$day_exposure_start), ]
  merged <- data[1, , drop = FALSE]
  for (i in 2:nrow(data)) {
    if (is.na(data$day_exposure_start[i]) || is.na(data$day_exposure_end[i])) {
      next
    }
    if (data$day_exposure_start[i] <= merged$day_exposure_end[nrow(merged)] + 1) {
      merged$day_exposure_end[nrow(merged)] <- max(merged$day_exposure_end[nrow(merged)], data$day_exposure_end[i], na.rm = TRUE)
    } else {
      merged <- rbind(merged, data[i, , drop = FALSE])
    }
  }
  return(merged)
}

# Apply the function to each ENROLID precipitant group
collapsed_df <- precipitant_cohort_9|>
  mutate(day_obs_end = as.numeric(day_obs_end)) |> 
  group_by(ENROLID, precipitant) |>
  do(merge_intervals(.)) |>
  ungroup() |> 
  select(ENROLID, precipitant, object, day_obs_start, day_obs_end,day_exposure_start, day_exposure_end) |>
  mutate(risk_window_start = if_else(day_obs_start >= day_exposure_start, day_obs_start, day_exposure_start)) |>
  mutate(risk_window_end = if_else(day_obs_end <= day_exposure_end, day_obs_end, day_exposure_end)) 

##Now, using this data, need to generate complete windows so unexposed periods are present. 


# Generate complete windows
generate_windows <- function(data) {
  max_obs_end <- max(data$day_obs_end)
  windows <- data.frame()
  
  for (i in 1:nrow(data)) {
    if (i == 1 && data$risk_window_start[i] > 0) {
      windows <- rbind(windows, data.frame(
        ENROLID = data$ENROLID[i],
        window_start = 0,
        window_end = data$risk_window_start[i] - 1,
        exposure = "Unexposed"
      ))
    }
    
    windows <- rbind(windows, data.frame(
      ENROLID = data$ENROLID[i],
      window_start = data$risk_window_start[i],
      window_end = data$risk_window_end[i],
      exposure = "Exposed"
    ))
    
    if (i < nrow(data) && data$risk_window_end[i] < data$risk_window_start[i + 1] - 1) {
      windows <- rbind(windows, data.frame(
        ENROLID = data$ENROLID[i],
        window_start = data$risk_window_end[i] + 1,
        window_end = data$risk_window_start[i + 1] - 1,
        exposure = "Unexposed"
      ))
    }
  }
  
  if (data$risk_window_end[nrow(data)] < max_obs_end) {
    windows <- rbind(windows, data.frame(
      ENROLID = data$ENROLID[nrow(data)],
      window_start = data$risk_window_end[nrow(data)] + 1,
      window_end = max_obs_end,
      exposure = "Unexposed"
    ))
  }
  
  return(windows)
}

# Apply the function to generate windows
windows_df <- collapsed_df |>
  group_by(ENROLID, precipitant) |>
  do(generate_windows(.)) |>
  ungroup()


# Loop for DDI

# ##Pre-test loop on one precipitant
# precip3 <- precipitant_cohort_9 |>
#   select(ENROLID, object, precipitant) |>
#   distinct() |>
#   left_join(windows_df, by = c("ENROLID", "precipitant")) |>
#   filter(precipitant == "Levothyroxine Sodium") |>
#   mutate(exposure = if_else(exposure == "Exposed", 1, 0))
# 
# precip4 <- precip3 %>%
#   left_join(dataset_for_loop_outcome, by = "ENROLID") %>%
#   rowwise() %>%
#   mutate(event_indicator = sum(c_across(starts_with("event_")) >= window_start & c_across(starts_with("event_")) <= window_end, na.rm = TRUE)) %>%
#   ungroup() %>%
#   mutate(event_indicator = replace_na(event_indicator, 0)) %>%
#   select(ENROLID, object, precipitant, window_start, window_end, exposure, event_indicator) %>%
#   mutate(time_at_risk = window_end - window_start + 1) %>%
#   mutate(offset_term = log(time_at_risk))
# 
# # Step 1: Identify individuals with discordant exposure periods
# discordant_individuals <- precip4 %>%
#   group_by(ENROLID) %>%
#   filter(n_distinct(exposure) > 1) %>%
#   ungroup()
# 
# # Convert ENROLID to a factor
# precip4$ENROLID <- as.factor(precip4$ENROLID)
# 
# # Fit the conditional Poisson regression model
# model <- gnm(event_indicator ~ exposure + offset(offset_term), eliminate = ENROLID, family = poisson, data = precip4)
# summary(model)



###REVISED LOOP#####
library(profvis)
library(rstanarm)

# Initialize the results tables
results_table <- data.frame()

for (i in precipitant_vector) {
  tryCatch({

 # Combine with original data
    precip3 <- precipitant_cohort_9 |> 
      select(ENROLID, object, precipitant) |> 
      distinct() |> 
      left_join(windows_df, by = c("ENROLID", "precipitant")) |> 
      filter(precipitant == i) |>  # Filter for the current precipitant
      mutate(exposure = if_else(exposure == "Exposed", 1, 0))

    precip4 <- precip3 |> 
      left_join(dataset_for_loop_outcome, by = "ENROLID") |> 
      rowwise() |>
      mutate(event_indicator = sum(c_across(starts_with("event_")) >= window_start & c_across(starts_with("event_")) <= window_end, na.rm = TRUE)) |> 
      ungroup() |> 
      mutate(event_indicator = replace_na(event_indicator, 0)) |> 
      select(ENROLID, object, precipitant, window_start, window_end, exposure, event_indicator) |> 
      mutate(time_at_risk = window_end - window_start + 1) |>
      mutate(offset_term = log(time_at_risk))
    
    # Convert ENROLID to a factor
    precip4$ENROLID <- as.factor(precip4$ENROLID)

    # Fit the conditional Poisson regression model
    model <- gnm(event_indicator ~ exposure + offset(offset_term), eliminate = ENROLID, family = poisson, data = precip4)

    # Extract model summary
    model_summary <- summary(model)
    
    # Extract coefficients and related statistics
    coefs <- coef(model_summary)
    coefs_exp <- exp(coef(model))
    confints <- confint(model)
    confints_exp <- exp(confints)
    
    # Create a data frame for combined results
    combined_df <- data.frame(
      Estimate = coefs[1],
      IRR = coefs_exp[1],
      SE = coefs[2],
      z_value = coefs[3],
      p_value = coefs[4],
      `Lower 95%` = confints_exp[1],
      `Upper 95%` = confints_exp[2],
      drug = i, 
      object_drug = oac
    )

    
    # Append to results tables
    results_table <- bind_rows(results_table, combined_df)

  }, error=function(e) {
    cat("ERROR :", conditionMessage(e), "\n")
  })
}

# Combine results tables and adjust p-values
# results_table3 <- bind_cols(results_table, results_table2$pr_z, results_table2$se_coef) |> janitor::clean_names()



results_table <- results_table|> janitor::clean_names()

adjusted_pval <- p.adjust(results_table$p_value, method = "fdr") |> as.data.frame() |> janitor::clean_names()

full_results_table <- bind_cols(results_table, adjusted_pval) |> 
  rename(adjusted_pval = p_adjust_results_table_p_value_method_fdr) |>
  mutate(across(where(is.numeric), ~ round(.x, 4))) |> 
  arrange(adjusted_pval)

final_results_table <- bind_rows(final_results_table, full_results_table)
}


final_results_table |> 
  filter(object_drug == "Apixaban")
```

# Semi-Bayes Shrinkage
```{r}

# Define the semi-Bayes shrinkage function
semi_bayes_shrinkage <- function(log_rr, se, prior_mean_log = 0, prior_var_log = 0.25) {
  # Calculate the precision (inverse of the variance)
  prior_precision = 1 / prior_var_log
  se_squared = se^2
  precision = 1 / se_squared
  
  # Calculate the posterior mean and variance
  post_precision = prior_precision + precision
  post_mean_log = (prior_mean_log * prior_precision + log_rr * precision) / post_precision
  post_var_log = 1 / post_precision
  
  # Calculate the shrunken log RR and confidence intervals
  shrunken_log_rr = post_mean_log
  lower_ci_log = post_mean_log - 1.96 * sqrt(post_var_log)
  upper_ci_log = post_mean_log + 1.96 * sqrt(post_var_log)
  
  return(data.frame(shrunken_log_rr, lower_ci_log, upper_ci_log))
}

# Apply the semi-Bayes shrinkage function to the regression results
shrinkage_results <- results_table %>%
  rowwise() %>%
  mutate(
    shrinkage = list(semi_bayes_shrinkage(Estimate, SE)),
    shrunken_log_rr = shrinkage$shrunken_log_rr,
    lower_ci_log = shrinkage$lower_ci_log,
    upper_ci_log = shrinkage$upper_ci_log,
    shrunken_irr = exp(shrunken_log_rr),
    lower_ci = exp(lower_ci_log),
    upper_ci = exp(upper_ci_log)
  ) %>%
  select(-shrinkage) %>%
  unnest(cols = c(shrunken_log_rr, lower_ci_log, upper_ci_log, shrunken_irr, lower_ci, upper_ci))

# Isolate statistically significant variables (where CI does not include 1)
significant_results <- shrinkage_results %>%
  filter(lower_ci > 1 | upper_ci < 1)


```


# Forest Plot

```{r}

# Define Theme
tm <- forest_theme(
  base_size = 10,
  ci_pch = 15,  # Confidence interval point shape
  ci_col = "#762a83",  # Confidence interval line color
  ci_fill = "black",  # Confidence interval fill color
  ci_alpha = 1,  # Confidence interval transparency
  ci_lty = 1,  # Confidence interval line type
  ci_lwd = 1.5,  # Confidence interval line width
  ci_Theight = 0.2,  # Set a "T" end at the end of CI
  refline_lwd = 2,  # Reference line width
  refline_lty = "dashed",  # Reference line type
  refline_col = "grey20",  # Reference line color
  vertline_lwd = 1,  # Vertical line width
  vertline_lty = "dashed",  # Vertical line type
  vertline_col = "grey20",  # Vertical line color
  summary_fill = "#4575b4",  # Change summary color for filling
  summary_col = "#4575b4",  # Change summary color for borders
  footnote_cex = 0.6,  # Footnote font size
  footnote_fontface = "italic",  # Footnote font face
  footnote_col = "blue"  # Footnote color
)

# Process data
forest_data <- shrinkage_results %>%
  filter(object_drug == "Apixaban") %>%
  select(drug, shrunken_irr, lower_ci, upper_ci) %>%
  rename(Drug = drug)

forest_data$` ` <- paste(rep(" ", 30), collapse = " ")
forest_data$`  ` <- paste(rep(" ", 2), collapse = " ")

forest_data <- forest_data |> 
  relocate(`  `, .after = 1) 

forest_data$`IRR (95% CI)` <- ifelse(
  is.na(forest_data$upper_ci), "", 
  sprintf("%.2f (%.2f to %.2f)", forest_data$shrunken_irr, forest_data$lower_ci, forest_data$upper_ci)
)

forest_data <- forest_data %>%
  arrange(desc(shrunken_irr))

# Create forest plot
p <- forest(
  forest_data %>% select(-c(lower_ci, upper_ci)),
  est = forest_data$shrunken_irr,
  lower = forest_data$lower_ci, 
  upper = forest_data$upper_ci,
  ref_line = 1, 
  ci_column = 3,
  arrow_lab = c("Protective", "Hazardous"),
  xlim = c(0, 6),
  footnote = "This is the demo data.", 
  theme = tm
)


ggsave("plot.png", plot = p, height = 55, width = 10, dpi = 330, limitsize = FALSE)


# Prepare data for forest plot
table_text <- cbind(
  forest_data$Drug,
  forest_data$`IRR (95% CI)`
)

# Create the forest plot
library(forestplot)
forestplot(
  table_text,
  mean = forest_data$shrunken_irr,
  lower = forest_data$lower_ci,
  upper = forest_data$upper_ci,
  new_page = TRUE,
  is.summary = c(rep(FALSE, nrow(forest_data))),
  clip = c(0, 5),
  xlog = FALSE,
  col = fpColors(box = "#762a83", lines = "#762a83", zero = "black"),
  xticks = c(0, 1, 2, 3, 4, 5),
  zero = 1,
  refline = 1,
  boxsize = 0.2,
  lineheight = unit(0.5, "cm"),
  graph.pos = 3,
  graphwidth = unit(10, "cm"),
  title = "Forest Plot of IRR (95% CI)",
  xlab = "IRR (95% CI)",
  txt_gp = fpTxtGp(label = gpar(cex = 0.8), ticks = gpar(cex = 0.8)),
                   # Increase the height of the plot
  vp = viewport(height = unit(1000 + 50 * nrow(forest_data), "cm"))  # Adjust the height as per the number of rows)
)
```

