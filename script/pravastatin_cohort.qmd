---
title: "cohort_building_2"
author: "Kent Hanson"
format: html
editor: visual
---

#To Do Need to redfine washout periods & grace period Need to plug in control (pravastatin) somehow

# About

The goal of this analysis is to explore DDI in CVD using the SCCS as a high-throughput screening technique

# Packages

```{r}
#| label: load-packages/functions
#| include: false

pacman::p_load(tidyverse, arrow, duckdb, tictoc, haven, reshape2, lubridate, SCCS, janitor, fs, here, AdhereR, remotes, lme4, gnm, survival, grid, forestploter, duckplyr, xlsx, data.table, progress, readxl, zoo, msm)

# Call functions
source(here("codes/functions.R"))
source(here("codes/codes.R"))

redbook <- open_dataset("//pharm-psop/Truven Data/Truven Data R/redbook.parquet") |> 
  collect()

```

# Drug Data

```{r}
# Retrieve NDCs for pravastatin using get_ndc_by_drug_name function
pravastatin_ndc <- get_ndc_by_drug_name("^Pravastatin Sodium") #need wildcard to exclude aspirin;pravastatin

# Process ccae & mdcr datasets using extract_oac_drug_data function
ccaed_2009_2021 <- extract_oac_drug_data (dataset_path = "//pharm-psop/Truven Data/Truven Data R/ccae/d", output_path = "C:/Users/kahanso2/Documents/doac-ddi/data/ccaed_2009_2021_pravastatin.parquet", ndc_filter = pravastatin_ndc)

mdcrd_2009_2021 <- extract_oac_drug_data (dataset_path = "//pharm-psop/Truven Data/Truven Data R/mdcr/d", output_path = "C:/Users/kahanso2/Documents/doac-ddi/data/mdcrd_2009_2021_pravastatin.parquet", ndc_filter = pravastatin_ndc)

# Bind drug files
all_drug <- bind_rows(ccaed_2009_2021, mdcrd_2009_2021) # 29,000,363 obs

# Save dataset so don't have to do that again
all_drug |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_drug_2009_2021_pravastatin.parquet")

# Open dataset
all_drug_2009_2021 <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_drug_2009_2021_pravastatin.parquet")

# Save unique IDs of oac users
all_pravastatin_users <- unique(all_drug_2009_2021$ENROLID) # 2,360,390 users

```

#Clean drug data

```{r}
# Apply data cleaning functions to oac drug dataset
cleaned_drug_data <- all_drug_2009_2021 |> 
  clean_canceling_claims() |> 
  remove_sequential_pairs() |> 
  select_max_fill() # 26,909,897 obs

# Save dataset so don't have to do that again
cleaned_drug_data |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/cleaned_drug_data_pravastatin.parquet")

# Open dataset
cleaned_drug_data <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/cleaned_drug_data_pravastatin.parquet")

```

# Assign Index Date

```{r}
#Apply functions to create index dates and age-eligible population
all_pravastatin_index <- cleaned_drug_data |> 
  calculate_drug_end_plus_grace(adherence_multiplier = 0.2) |> 
  flag_gaps_and_assign_episodes(gap_allowed = 183) |> 
  assign_index_date_and_med() |> 
  filter_new_users_age(earliest_index_date = '2009-07-02', age_criteria = 18)
  
#Extract unique IDs of OAC users meeting criteria  
all_drug_index_ids <- unique(all_pravastatin_index$ENROLID) #2181236

```

# Continuous enrollment

```{r}
# Write parquet file for patients 18+ with index date and ENROLID for CE assessment
all_pravastatin_index |>
  arrange(ENROLID, index_date) |> 
  select(ENROLID, index_date) |> 
  distinct() |> 
  write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ids_with_indexdate_pravastatin.parquet")

# Read in dataset with ENROLID & index_date
cohort_ids_for_CE <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ids_with_indexdate_pravastatin.parquet")

# Extract relevant ENROLIDs for CE assessment
cont_enrollment_ids <- unique(cohort_ids_for_CE$ENROLID) 

#Open relevant T files for CE scanning; filter for specific ids

load_enrollment_data <- function(path, ids) {
  open_dataset(path) |>
    select(ENROLID, DTSTART, DTEND) |> 
    to_duckdb() |> 
    filter(ENROLID %in% ids) |> 
    collect()
}

ccae_enroll <- load_enrollment_data("//pharm-psop/Truven Data/Truven Data R/ccae/t", cont_enrollment_ids)
mdcr_enroll <- load_enrollment_data("//pharm-psop/Truven Data/Truven Data R/mdcr/t", cont_enrollment_ids) 

all_enroll <- bind_rows(ccae_enroll, mdcr_enroll) #131847282

# Create parquet file of T datasets with relevant IDs
all_enroll |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/enrollment_parquet_pravastatin.parquet") 

# Read parquet file back into the environment
enrollment_parquet <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/enrollment_parquet_pravastatin.parquet") 

# Apply Continuous Enrollment function
continuous_enrollment_result <- ContinuousEnrollment(
    enrollment_data = enrollment_parquet,
    data = cohort_ids_for_CE,
    days_after = 0,
    days_before = 183,
    max_gap = 0,
    index_date_var = index_date
)  

#Save IDs with CE as vector
ids_with_ce <- unique(continuous_enrollment_result$ENROLID) #1467834 (25% drop)

```

# Outcome Identification

```{r}

# Define a function for event identification and trauma exclusion
identify_bleed_outcome <- function(dataset_path_s, dataset_path_i, dataset_path_o, output_path_event) {
  
# Filter and collect ccaes cases with transfusion in REVCODE 
transfusion_data <- open_dataset(dataset_path_s) |> 
  select(ENROLID, YEAR, ADMDATE, DISDATE, REVCODE) |> 
  to_duckdb() |> 
  filter(ENROLID %in% ids_with_ce, REVCODE %in% c("0390", "0391")) |> 
  mutate(transfusion_code = 1) |> #Create var indicating transfusion code 1. Don't care which code it is
  select(-REVCODE) |> 
  distinct() |> 
  collect() #121580 distinct oac users had a transfusion code (~9%)


# Collect the full inpatient data with relevant variables
inpatient_transfusion_data <- open_dataset(dataset_path_i, unify_schemas = TRUE) |> 
  select(c(ENROLID, YEAR, ADMDATE, AGE, DAYS, DISDATE, DXVER, PDX, DX1:DX15, PROC1:PROC15)) |> 
  to_duckdb() |> 
  filter(ENROLID %in% ids_with_ce) |>
  collect() |>  
  left_join(transfusion_data, by = c("ENROLID", "YEAR", "ADMDATE", "DISDATE")) |> 
  replace_na(list(DXVER = "9")) |> 
  filter(DXVER != "") |> #removes blanks that probably indicate ambulance services (at this did for 4082398001)
  mutate(DXVER = as.numeric(DXVER)) #627789 unique

# Identify patients who meet bleed definition outlined by Dhopshewarkar et al
inpatient_bleed_data <- inpatient_transfusion_data |> 
  mutate(
    bleed_code = if_else(
      DXVER == 9, 
      if_any(PDX, ~str_detect(.x, {{all_icd9_bleeds_ind}})) |
        (if_any(PDX, ~str_detect(.x, {{all_gib_icd9_possible}})) &
           (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}})) |
              !is.na(transfusion_code))) | 
      (if_any(PDX, ~str_detect(.x, {{all_unspec_icd9_possible}})) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}})))) |
      (if_any(PDX, ~ gu_icd9_possible %in% .x)  &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_icd9_bleeds_ind}}))) &
         (if_any(DX2:DX15, ~str_detect(.x, {{all_comb_sec}})))),
      if_else(
        DXVER == 0, 
        if_any(PDX, ~str_detect(.x, {{all_icd10_bleeds_ind}})) |
          (if_any(PDX, ~str_detect(.x, {{all_gib_icd10_possible}})) &
             (if_any(DX2:DX15, ~str_detect(.x, {{all_icd10_bleeds_ind}})) |
                !is.na(transfusion_code))) | 
          (if_any(PDX, ~str_detect(.x, {{all_unspec_icd10_possible}})) &
             (if_any(DX2:DX15, ~str_detect(.x, {{all_icd10_bleeds_ind}})))),
        NA
      )
    )
  ) |>
  group_by(ENROLID) |> 
  mutate(bleed_ever = as.integer(any(bleed_code))) |> 
  filter(bleed_ever == 1) |> 
  ungroup()

inpatient_trauma <- inpatient_bleed_data |> 
  mutate(
    trauma_code = if_else(
      DXVER == 9,
      if_any(DX1:DX15, ~str_detect(.x, {{trauma_check_icd9}})) |
        if_any(PROC1:PROC15, ~str_detect(.x, {{trauma_hcpcs_all}})), 
      if_else(
        DXVER == 0,
        if_any(DX1:DX15, ~str_detect(.x, {{trauma_check_icd10}})) |
          if_any(PROC1:PROC15, ~str_detect(.x, {{trauma_hcpcs_all}})),
        NA
      )
    )
  ) |> 
  select(ENROLID, ADMDATE, DXVER, trauma_code) |> 
  filter(trauma_code == TRUE) |> 
  mutate(source = "inpatient") |>  #34762
  select(ENROLID, ADMDATE)

#Above collects patients who had an inpatient bleed event. Need to pull them into outpatient dataset to search for trauma
outcome_enrolid <- unique(inpatient_bleed_data$ENROLID)

# Identify trauma in outpatient dataset
outpatient_trauma <- open_dataset(dataset_path_o, unify_schemas = TRUE) |> 
  select(ENROLID, SVCDATE, DXVER, DX1, DX2, DX3, DX4, PROC1) |> 
  to_duckdb() |> 
  filter(ENROLID %in% outcome_enrolid) |> 
  collect() |>  #97565595 obs
  replace_na(list(DXVER = "9")) |> 
  filter(DXVER != "") |> #removes blanks that probably indicate ambulance services (at this did for 4082398001)
  mutate(DXVER = as.numeric(DXVER)) |> 
  mutate(trauma_code = if_else(
      DXVER == 9,
      if_any(DX1:DX4, ~str_detect(.x, {{trauma_check_icd9}})) |
        if_any(PROC1, ~str_detect(.x, {{trauma_hcpcs_all}})), 
      if_else(
        DXVER == 0,
        if_any(DX1:DX4, ~str_detect(.x, {{trauma_check_icd10}})) |
          if_any(PROC1, ~str_detect(.x, {{trauma_hcpcs_all}})),
        NA
      )
    )
  ) |>  #97467343 obs
  select(ENROLID, SVCDATE, DXVER, trauma_code) |> 
  filter(trauma_code == TRUE) |> 
  mutate(ADMDATE = SVCDATE, source = "outpatient") |> 
  select(ENROLID, ADMDATE) #786154 obs
  
# Combine trauma codes
all_trauma_codes <- bind_rows(inpatient_trauma, outpatient_trauma) |> 
  distinct() |> 
  arrange(ENROLID, ADMDATE) |>  #238530 obs
  rename(trauma_date = ADMDATE)

#Join trauma codes with main dataset; identify exclusion events (i.e., those with trauma 1d before through 1d post ADMDATE)
inpatient_bleed_trauma_merged <- inpatient_bleed_data |> 
  left_join(all_trauma_codes, by = "ENROLID") |> 
   mutate(
    within_window = (ADMDATE - 1 <= trauma_date & trauma_date <= ADMDATE + 1)
  ) |> # 2087406 obs
  filter(within_window) |> # 42386 obs
  distinct(ENROLID, ADMDATE) |> # 39010 obs
  mutate(exclusion_event = 1) 


#Join the dataset back to original dataset and then filter out exclusion events
bleed_outcome_no_trauma <- inpatient_bleed_data |> 
  left_join(inpatient_bleed_trauma_merged, by = c("ENROLID", "ADMDATE")) |> 
  filter(bleed_code == TRUE) |> #305038 obs
  filter(is.na(exclusion_event)) #20917 unique obs

#Save dataset so don't have to do that again. Need to re-save in correct folder before uploading to github
bleed_outcome_no_trauma |> write_parquet(output_path_event)

}

#Call function for ccae & mdcr
ccae_bleed_outcome_no_trauma <- identify_bleed_outcome(
  dataset_path_s = "//pharm-psop/Truven Data/Truven Data R/ccae/s",
  dataset_path_i = "//pharm-psop/Truven Data/Truven Data R/ccae/i",
  dataset_path_o = "//pharm-psop/Truven Data/Truven Data R/ccae/o",
  output_path_event = "C:/Users/kahanso2/Documents/doac-ddi/data/ccae_bleed_outcome_no_trauma_pravastatin.parquet")

mdcr_bleed_outcome_no_trauma <- identify_bleed_outcome(
  dataset_path_s = "//pharm-psop/Truven Data/Truven Data R/mdcr/s",
  dataset_path_i = "//pharm-psop/Truven Data/Truven Data R/mdcr/i",
  dataset_path_o = "//pharm-psop/Truven Data/Truven Data R/mdcr/o",
  output_path_event = "C:/Users/kahanso2/Documents/doac-ddi/data/mdcr_bleed_outcome_no_trauma_pravastatin.parquet")


#Open datasets
ccae_bleed_outcome_no_trauma <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/ccae_bleed_outcome_no_trauma_pravastatin.parquet")

mdcr_bleed_outcome_no_trauma <- read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/mdcr_bleed_outcome_no_trauma_pravastatin.parquet")

#Merge event files
all_outcome <- bind_rows(ccae_bleed_outcome_no_trauma, mdcr_bleed_outcome_no_trauma) |> 
  arrange(ENROLID, ADMDATE) |> 
  group_by(ENROLID) |> 
  mutate(hospnum = row_number()) |> 
  ungroup() |> 
  mutate(eventnum= row_number()) |> 
  select(c(ENROLID, ADMDATE, DAYS, DISDATE, hospnum, eventnum)) 

all_outcome |> write_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_inpatient_bleed_no_trauma_pravastatin.parquet")

all_inpatient_bleed_no_trauma <-  read_parquet("C:/Users/kahanso2/Documents/doac-ddi/data/all_inpatient_bleed_no_trauma_pravastatin.parquet")

#Create vector that includes ENROLID of all individuals who experienced outcome in 2009-2021
#outcome_vec <- all_inpatient_bleed_no_trauma$ENROLID #1297106

#Shouldn't this be distinct obs? 
outcome_vec <- unique(all_inpatient_bleed_no_trauma$ENROLID) #68485

```

#Test for days between fills

```{r}
# #Evaluate days between fills by drug to get avg. this will be rough and be goofy if people switch and then switch back
# days_between_fills <- test_2 %>%
#   filter(ENROLID %in% outcome_vec) |> 
#   group_by(ENROLID, GENNME) %>%
#   arrange(ENROLID, GENNME, SVCDATE, episode_number) %>%
#   mutate(
#     # Calculate the days between the current fill and the previous fill
#     days_between_fills = as.numeric(difftime(SVCDATE, lag(SVCDATE), units = "days")) - lag(DAYSUPP),
#     # Adjust for overlapping fills (set negative values to zero)
#     days_between_fills = if_else(days_between_fills < 0, 0, days_between_fills)
#   ) %>%
#   # Remove the first row of each group (since lag creates an NA for the first row)
#   filter(!is.na(days_between_fills)) %>%
#   # # Calculate the mean days between fills for each drug
#   # group_by(GENNME) %>%
#   # summarise(mean_days_between_fills = IQR(days_between_fills, na.rm = TRUE)) %>%
#   ungroup() |> 
#   filter(days_between_fills <50)
# 
# # Plot the histogram
# ggplot(days_between_fills, aes(x = days_between_fills)) +
#   geom_histogram(binwidth = 5, fill = "blue", color = "black") +
#   facet_wrap(~ GENNME, scales = "free_y") +
#   labs(
#     title = "Distribution of Days Between Fills",
#     x = "Days Between Fills",
#     y = "Frequency"
#   ) +
#   theme_minimal()
```

# Apply continuous exposure rules

```{r}

# Function to apply continuous exposure rule (i.e., identify when exposure ends )
apply_continuous_exposure_rules <- function(data, outcome_ids) {
  
  #Step 1: Filter cohort based on outcome IDs
  oac_cohort <- data |> 
    filter(ENROLID %in% outcome_ids)
  
  #Step 2: Apply continuous exposure logic
  continuous_exposure_data <- oac_cohort |> 
    group_by(ENROLID, episode_number) |> 
    mutate(
      obj_end_lagged = lag(drug_end_plus_grace), 
      cont_expo1 = if_else(SVCDATE <= obj_end_lagged, "Continuous", "New" ),  #Flag if next fill falls outside grace period
      cont_expo2 = if_else(is.na(cont_expo1), "New", cont_expo1),  #Change first fill values (currently NA) to "New"
      censor = ifelse(cont_expo1=="New" & cont_expo2 == "New", 1, NA)) |>   #Filter if "New", "New". Occurs if new start that isnt 1st fill
    fill(censor) |>  #Fills down the censored variables for filtering; 243201
    ungroup() |> 
    filter(is.na(censor)) |> 
    filter(oac_switch == "match") #filter out obs after switch occurs
  
  #Step 3: Create a cohort of OAC users
  oac_users <- continuous_exposure_data |> 
    group_by(ENROLID, episode_number) |> 
    mutate(obj_period_end = max(drug_end_plus_grace)) |> 
    ungroup() |> 
    select(ENROLID, GENNME, age_at_index, SEX, index_date, obj_period_end, episode_number)  |> 
    distinct(ENROLID, episode_number, .keep_all = TRUE) 
  
  return(oac_users)
}

# Apply function to index dataset
pravastatin_users <- apply_continuous_exposure_rules(all_pravastatin_index, outcome_vec)


## Extract unique ENROLIDs
pravastatin_user_ids <- unique(pravastatin_users$ENROLID) #28009


```

#Chunk to evaluate stop of follow-up (disenrollment)

```{r}

# Function to evaluate disenrollment (i.e., censor at gap in enrollment)
evaluate_disenrollment <- function(enrollment_data, user_ids) {
  
  #Step 1: Calculate gaps and flag when disenrollment occurs
  disenrollment_data <- enrollment_data |> 
  filter(ENROLID %in% user_ids) |> 
  select(ENROLID, DTSTART, DTEND) |> 
  arrange(ENROLID, DTSTART) |> 
  group_by(ENROLID) |> 
  mutate(
    PreviousEndDate = lag(DTEND),
    GapDays = as.integer(DTSTART - PreviousEndDate)) |>  # Get prior DTEND and calculate gap b/n DTSTART
  ungroup() |> 
  left_join(pravastatin_users, by = "ENROLID") |> #Join with dataset w/ observation start time
  group_by(ENROLID, episode_number) |> 
  mutate(flag = if_else(DTSTART < index_date - 30, 1, 0)) |> #Flag to identify if DTSTART is 30d before index
  filter(flag == 0) |> # filters them patients out
  mutate(
    censor_dt = if_else(GapDays > 30 & PreviousEndDate > index_date, 1, 0),  #Creates censoring variable gap >30d & prior end date is after index
    censor_dt = cummax(censor_dt) # Propagate the censor flag to all subsequent rows
  ) |> 
  filter(censor_dt == 0) |> 
  mutate(lost_ce_dt = max(DTEND)) |> #Use max date populate all rows with day of disenrollment
  ungroup() |> 
  distinct(ENROLID, index_date, obj_period_end, lost_ce_dt, episode_number) |> 
  group_by(ENROLID, episode_number) |> 
  mutate(new_obj_period_end = pmin(lost_ce_dt, obj_period_end, na.rm = TRUE)) |> 
  ungroup() |> 
  select(ENROLID, episode_number, new_obj_period_end)

  # Step 2: Update the follow-up period based on disenrollment
  updated_cohort <- pravastatin_users |> 
    left_join(disenrollment_data, by = c("ENROLID", "episode_number")) |> 
    select(-obj_period_end) |> 
    rename(obj_period_end = new_obj_period_end)
  
  return(updated_cohort)
}

# Apply function
cohort_pravastatin_users_with_ce_update <- evaluate_disenrollment(enrollment_parquet, pravastatin_user_ids)


```

# I think this chunk is trash

```{r}
analytic_cohort_oac <- left_join(cohort_pravastatin_users_with_ce_update, all_inpatient_bleed_no_trauma , by = "ENROLID") |> 
  arrange(ENROLID, ADMDATE, episode_number) |> 
  mutate(day_obs_start = 0) |> 
  mutate(day_obs_end = obj_period_end - index_date_2) |> 
  mutate(day_of_event = ADMDATE - index_date_2) |> 
  #mutate(event_occur_before_obs = ADMDATE < index_date) |> 
  mutate(event_occur_outside_obs = ADMDATE < index_date_2 | ADMDATE > obj_period_end) |> 
  filter(event_occur_outside_obs==FALSE) |>  #17103 (all doac); 5767 obs
  group_by(ENROLID) %>%
  filter(episode_number == min(episode_number)) %>% #only allows for minimum episode number for each person (no re-entry)
  ungroup() |> 
  mutate(object = GENNME) |> 
  select(c(-GENNME, -event_occur_outside_obs)) |> 
  mutate(age_group = case_when(
    age_at_index_2 >= 18 & age_at_index_2 <= 44 ~ "18-44",
    age_at_index_2 >= 45 & age_at_index_2 <= 64 ~ "45-64",
    age_at_index_2 >= 65 & age_at_index_2 <= 74 ~ "65-74",
    age_at_index_2 >= 75 & age_at_index_2 <= 84 ~ "75-84",
    age_at_index_2 >= 85 & age_at_index_2 <= 90 ~ "85-90",
    age_at_index_2 > 90 ~ ">90",
    TRUE ~ "Other"
  ))

#How many patients had an event before observation
cohort_ids <- unique(analytic_cohort_oac$ENROLID)
  
event_before_obs_test <- left_join(cohort_oac_users_with_ce_update, all_inpatient_bleed_no_trauma , by = "ENROLID") |> 
  filter(ENROLID %in% cohort_ids) |> 
  arrange(ENROLID, ADMDATE) |> 
  mutate(day_obs_start = 0) |> 
  mutate(day_obs_end = obj_period_end - index_date_2) |> 
  mutate(day_of_event = ADMDATE - index_date_2) |> 
  mutate(event_occur_before_obs = ADMDATE < index_date_2) 

event_before_obs_test |> distinct(ENROLID) #12308
event_before_obs_test |> filter(event_occur_before_obs == TRUE) |> distinct(ENROLID) #2497 had prior event

# Count the number of events before the index date for each ENROLID
event_count_before_index <- event_before_obs_test |> 
  filter(event_occur_before_obs == TRUE) |>  # Only include events before the index date
  group_by(ENROLID) |> 
  summarise(event_count = n()) |>  # Count the number of events before the index date
  ungroup()

# Calculate the proportions
event_proportions <- event_count_before_index |> 
  group_by(event_count) |> 
  summarise(patient_count = n()) |>  # Count how many patients had each number of events
  mutate(proportion = patient_count / sum(patient_count)) |>  # Calculate the proportion
  arrange(event_count)  # Arrange by the number of events

```

#Build Table 1

```{r}
# Calculate unique person-days
person_days_data <- analytic_cohort_oac %>%
  select(ENROLID, object, day_obs_start, day_obs_end) %>%
  distinct() %>%
  group_by(object, ENROLID) %>%
  summarise(total_person_days = sum(day_obs_end - day_obs_start, na.rm = TRUE), .groups = 'drop')

# Calculate the proximity of the event to the end of follow-up
proximity_obs_end_summary <- analytic_cohort_oac %>%
  mutate(proximity_to_end = as.numeric(day_obs_end - day_of_event)) |> 
  group_by(object) %>%
  summarise(
    mean_proximity_end = mean(proximity_to_end, na.rm = TRUE),
    sd_proximity_end = sd(proximity_to_end, na.rm = TRUE),
    .groups = 'drop'
  )

# Calculate the proximity of the event to the end of follow-up
proximity_obs_st_summary <- analytic_cohort_oac %>%
  mutate(proximity_to_st = as.numeric(day_of_event - day_obs_start)) |> 
  group_by(object) %>%
  summarise(
    mean_proximity_st = mean(proximity_to_st, na.rm = TRUE),
    sd_proximity_st = sd(proximity_to_st, na.rm = TRUE),
    .groups = 'drop'
  )

# Summarize other statistics
summary_table <- analytic_cohort_oac %>%
  group_by(object) %>%
  summarise(
    number_of_cases = n_distinct(ENROLID),
    number_of_events = n(),
    n_female = sum(SEX == 2),
    perc_female = mean(SEX == 2) * 100,
    mean_age = mean(age_at_index, na.rm = TRUE),
    sd_age = sd(age_at_index, na.rm = TRUE),
    age_18_44 = sum(age_group == "18-44"),
    age_45_64 = sum(age_group == "45-64"),
    age_65_74 = sum(age_group == "65-74"),
    age_75_84 = sum(age_group == "75-84"),
    age_85_90 = sum(age_group == "85-90"),
    .groups = 'drop'
  )

# Combine the person-days data and proximity summary with the summary statistics
summary_table <- summary_table %>%
  left_join(person_days_data %>%
              group_by(object) %>%
              summarise(person_days = sum(total_person_days, na.rm = TRUE), .groups = 'drop'),
            by = "object") %>%
  left_join(proximity_obs_end_summary, by = "object") %>%
  left_join(proximity_obs_st_summary, by = "object") |> 
  mutate(
    n_perc_female = paste0(n_female, " (", round(perc_female, 2), "%)"),
    mean_sd_age = paste0(round(mean_age, 2), " (", round(sd_age, 2), ")"),
    mean_sd_proximity_st = paste0(round(mean_proximity_st, 2), " (", round(sd_proximity_st, 2), ")"),
    mean_sd_proximity_end = paste0(round(mean_proximity_end, 2), " (", round(sd_proximity_end, 2), ")"),
  ) %>%
  select(
    object, number_of_cases, person_days, number_of_events,
    n_perc_female, mean_sd_age, age_18_44, age_45_64,
    age_65_74, age_75_84, age_85_90, mean_sd_proximity_st, mean_sd_proximity_end
  )

summary_table
```

# Create analytic cohort

```{r}
# Generate the analytic cohort with the people to be evaluated

analytic_cohort_pravastatin <- left_join(cohort_pravastatin_users_with_ce_update, all_inpatient_bleed_no_trauma , by = "ENROLID") |> 
  arrange(ENROLID, ADMDATE, episode_number) |> 
  mutate(day_obs_start = 0) |> 
  mutate(day_obs_end = obj_period_end - index_date) |> 
  mutate(day_of_event = ADMDATE - index_date) |> 
  #mutate(event_occur_before_obs = ADMDATE < index_date) |> 
  mutate(event_occur_outside_obs = ADMDATE < index_date | ADMDATE > obj_period_end) |> 
  filter(event_occur_outside_obs==FALSE) |>  #17103 (all doac); 5767 obs
  group_by(ENROLID) %>%
  filter(episode_number == min(episode_number)) %>% #only allows for minimum episode number for each person (no re-entry)
  ungroup() |> 
  mutate(object = GENNME) |> 
  select(c(-GENNME, -event_occur_outside_obs)) |> 
  mutate(age_group = case_when(
    age_at_index >= 18 & age_at_index <= 44 ~ "18-44",
    age_at_index >= 45 & age_at_index <= 64 ~ "45-64",
    age_at_index >= 65 & age_at_index <= 74 ~ "65-74",
    age_at_index >= 75 & age_at_index <= 84 ~ "75-84",
    age_at_index >= 85 & age_at_index <= 90 ~ "85-90",
    age_at_index > 90 ~ ">90",
    TRUE ~ "Other"
  ))

ids_precip_list <- unique(analytic_cohort_pravastatin$ENROLID)
```

# Generate outcome datasets for each object drug

```{r}
#Generate outcome datsets for each object

create_pravastatin_dataset_for_loop_outcome <- function(pravastatin) {
  analytic_cohort_pravastatin_filtered <- analytic_cohort_pravastatin |> 
    filter(object == pravastatin)
  
  ids_for_loop <- unique(analytic_cohort_pravastatin$ENROLID)
  
  dataset_for_loop <- analytic_cohort_pravastatin_filtered |> 
  arrange(ENROLID, ADMDATE) |> 
  distinct(ENROLID, .keep_all = TRUE) |> 
  select(ENROLID, index_date, obj_period_end, day_obs_start, day_obs_end, object, episode_number)
  
  dataset_for_loop_outcome <- analytic_cohort_pravastatin_filtered |> 
  arrange(ENROLID, ADMDATE) |> 
  select(ENROLID, day_of_event, episode_number) |> 
  distinct() |> #10 duplicates (i.e., multiple events same day)
  group_by(ENROLID, episode_number) |>
  mutate(event_number = row_number()) |>
  ungroup() |> 
  pivot_wider(
    id_cols = c(ENROLID, episode_number),  
    names_from = event_number, 
    values_from = day_of_event,
    names_prefix = "event_"
  )
  
  # Return both datasets as a list
  return(list(dataset_for_loop = dataset_for_loop, dataset_for_loop_outcome = dataset_for_loop_outcome))
  
}

outcome_loops_pravastatin <- create_pravastatin_dataset_for_loop_outcome("Pravastatin Sodium")


#Pull each cohort from the list
# dataset for loop
dataset_for_loop_pravastatin <- outcome_loops_pravastatin$dataset_for_loop

# Pull each outcome dataset from the list
dataset_for_loop_outcome_pravastatin <- outcome_loops_pravastatin$dataset_for_loop_outcome

```

# Get full concomitant drug data for each object

```{r}
# Function to get full list of drugs used by patients in cohort
process_dataset <- function(dataset_path) {
  drug_data <- open_dataset(dataset_path) |> 
    select(c(ENROLID, NDCNUM, SVCDATE, YEAR, AGE, SEX, DAYSUPP))|>
    to_duckdb() |> 
    filter(ENROLID %in% ids_precip_list) |> 
    collect()
  
  dataset_names <- drug_data |> 
    left_join(redbook, by = "NDCNUM") |>  
    select(c(ENROLID, NDCNUM, SVCDATE, YEAR, AGE, SEX, DAYSUPP, THRDTDS, GENNME, MASTFRM)) 
  
  return(dataset_names)
}

# Process ccae & mdcr datasets
ccaed_2009_2021_full <- process_dataset(dataset_path = "//pharm-psop/Truven Data/Truven Data R/ccae/d")
mdcrd_2009_2021_full <- process_dataset(dataset_path = "//pharm-psop/Truven Data/Truven Data R/mdcr/d")

#Bind drug files
all_drug_full <- bind_rows(ccaed_2009_2021_full, mdcrd_2009_2021_full) 


#############

object_pravastatin <- "Pravastatin Sodium"
# Define function to collect this for each OAC
pravastatin_precipitant_processing <- function(pravastatin){

# Select object drug to analyze
  precipitant_cohort <- analytic_cohort_pravastatin |> 
    filter(object == pravastatin) |> 
    arrange(ENROLID, ADMDATE) |> 
    distinct(ENROLID, .keep_all = TRUE) |>  
    select(ENROLID, object, index_date, obj_period_end, day_obs_start, day_obs_end, episode_number)
  
# Pare down all_drug_full for only ids above
  pravastatin_specific_precipitants <- all_drug_full |> 
    filter(ENROLID %in% precipitant_cohort$ENROLID)

#Join ENROLID with entire drug data file to pull in Rx history. Filter for drugs used in obj_wind
precipitant_cohort_2 <- left_join(precipitant_cohort, pravastatin_specific_precipitants, by = "ENROLID") |> #595155
  arrange(ENROLID, SVCDATE) |> 
  mutate(precip_start = SVCDATE) |> 
  mutate(precip_end = round((SVCDATE + DAYSUPP) + (DAYSUPP * 0.2))) |> 
  mutate(
    concom = if_else(
      (precip_start <= obj_period_end & precip_end >= index_date), 1, 0
    )) |> 
  filter(concom ==1) |> 
  mutate(pravastatin = if_any(GENNME,~ str_detect(.x, paste(object_pravastatin, collapse = "|")))) |> 
  filter(pravastatin ==FALSE) |> 
  select(-pravastatin) 
  
  #Filter out the drugs from the exclusion list plus a few additional outliers
precipitant_cohort_3 <- precipitant_cohort_2|> 
  filter(!MASTFRM %in% excluded_mastfrm) |>
  filter(!THRDTDS %in% excluded_thrdtds) |> 
  filter(!str_detect(THRDTDS, "S/M")) |> 
  filter(!GENNME %in% excluded_gennme)

#Pull out the individual drugs. Split out combination products
precipitant_active_ingredients <- precipitant_cohort_3 |> 
  separate(GENNME, into = paste0("col", 1:10), sep = "/", fill = "right") |> 
  pivot_longer(cols = starts_with("col"), names_to = "name", values_to = "GENNME", values_drop_na = TRUE, names_repair = "unique") |> 
  separate(GENNME, into = paste0("drug", 1:10), sep = ";", fill = "right") |> 
  pivot_longer(cols = starts_with("drug"), names_to = "name2", values_to = "GENNME", values_drop_na = TRUE, names_repair = "unique") |> 
  filter(!is.na(GENNME)) |> 
  select(ENROLID, GENNME)
  
# Write the precipitants dataframe to an Excel file to allow manual renaming for mismatches
#write.xlsx(precipitant_active_ingredient, file = "precipitant_active_ingredient.xlsx")

# Created a mapping pathway for drugs used with ANY OAC. Read in here
drug_mapping <- read_excel("drug_mapping.xlsx")

#First use the mapping to correct names in the drug list 
precipitant_active_ingredient_mapped <- precipitant_active_ingredients |> 
  left_join(drug_mapping, by = "GENNME") |> 
  mutate(GENNME = if_else(is.na(NEWNAME), GENNME, NEWNAME)) |> 
  select(-NEWNAME)

# Count unique ENROLID for each drug and limit drug list to those used among 5+ unique people
drug_counts <- precipitant_active_ingredient_mapped %>%
  group_by(GENNME) %>%
  summarise(unique_enrolid_count = n_distinct(ENROLID)) |> 
  filter(unique_enrolid_count > 4)

# Save as a vector for future use in a loop
precipitant_vector <- unique(drug_counts$GENNME)


#Next use the mapping to correct names in the precipitant dataset. 
##First derive function
replace_drug_names_in_string <- function(drug_string, mapping) {
  for (i in 1:nrow(mapping)) {
    drug_string <- gsub(mapping$GENNME[i], mapping$NEWNAME[i], drug_string, fixed = TRUE)
  }
  return(drug_string)
}

# Apply the function to the GENNME column in the main dataset
precipitant_cohort_4 <- precipitant_cohort_3 %>%
  mutate(GENNME = sapply(GENNME, replace_drug_names_in_string, mapping = drug_mapping))


##APPLY DRUG CLEANING FUNCTION
precipitant_cohort_cleaned <- precipitant_cohort_4 |> 
  clean_canceling_claims() |> 
  remove_sequential_pairs() |> 
  select_max_fill() 


##Creates days of exposure start and end, but it creates problems when there are negative ds
precipitant_cohort_9 <- precipitant_cohort_cleaned |> 
  rename(expo_start_date = SVCDATE) |> 
  rename(expo_end_date = precip_end) |> 
  rename(precipitant=GENNME) |> 
  select(ENROLID, object, day_obs_start, day_obs_end, index_date, obj_period_end, precipitant, expo_start_date, expo_end_date, episode_number) |> 
  mutate(day_exposure_start = as.numeric(expo_start_date - index_date)) |> 
  filter(day_exposure_start <= day_obs_end) |> 
  mutate(day_exposure_end = as.numeric(expo_end_date - index_date)) |> 
  filter(day_exposure_end >= 0) |> 
  mutate(nsaid = if_any(precipitant, ~ str_detect(.x, paste(nsaids, collapse = "|")))) |> 
  mutate(antiplatelet = if_any(precipitant, ~ str_detect(.x, paste(antiplatelet, collapse = "|")))) |> 
  mutate(other_anticoag = if_any(precipitant, ~ str_detect(.x, paste(other_anticoag, collapse = "|")))) |>
  mutate(ssri_snri = if_any(precipitant, ~ str_detect(.x, paste(ssri_snri, collapse = "|")))) |>
  mutate(giprotect = if_any(precipitant, ~ str_detect(.x, paste(giprotect, collapse = "|")))) |>
  mutate(anticoagulant = if_any(precipitant, ~ str_detect(.x, paste(anticoagulant, collapse = "|")))) |> 
  arrange(ENROLID, day_obs_start)

return(list(cohort = precipitant_cohort_9, vector = precipitant_vector))
}

# Initialize a list to store the results for each pravastatin
pravastatin_results <- list()

# Run the function for each pravastatin and store both the cohort and the vector
pravastatin_results$pravastatin<- pravastatin_precipitant_processing("Pravastatin Sodium")

#Pull each cohort from the list
# Access the cohort for Apixaban
pravastatin_cohort <- pravastatin_results$pravastatin$cohort

# Access the precipitant vector for each
pravastatin_vector <- pravastatin_results$pravastatin$vector

```

# Run loop to do SCCS for each object drug

```{r}
# Define function with for loop inside
loop_function <- function (data, vector, outcome_dataset){ 
  
## Function to add in covariates
generate_covariate_data <- function(data, covariate_col) {
  data %>%
    filter(!!sym(covariate_col) == TRUE) %>%
    rowwise() %>%
    mutate(days = list(day_obs_start:day_obs_end)) %>%
    unnest(cols = c(days)) %>%
    group_by(ENROLID, days) %>%
    mutate(
      exposure_flag = if_else(
        any(days >= day_exposure_start & days <= day_exposure_end), 1, 0
      )
    ) %>%
    ungroup() %>%
    distinct(ENROLID, object, days, exposure_flag) %>%
    rename(!!paste0(covariate_col, "_exposed") := exposure_flag)
}

# Apply the function to generate each covariate drug datasets
nsaid_data <- generate_covariate_data(pravastatin_cohort, "nsaid")
antiplatelet_data <- generate_covariate_data(data, "antiplatelet")
other_anticoag_data <- generate_covariate_data(data, "other_anticoag")
ssri_snri_data <- generate_covariate_data(data, "ssri_snri")
giprotect_data <- generate_covariate_data(data, "giprotect")
anticoagulant_data <- generate_covariate_data(pravastatin_cohort, "anticoagulant")

# Function to expand the observation period and mark exposure
# Define your function to expand the observation period and mark exposure
expand_and_mark_exposure <- function(data, precipitant_name, outcome_dataset) {
  
  # Expand observation period to create a row for each day in observation window
  expanded_data <- data %>%
    rowwise() %>%
    mutate(days = list(day_obs_start:day_obs_end)) %>%
    unnest(cols = c(days)) |> 
    ungroup() 
  
  # Mark exposure period based on precipitant match and day range
  expanded_data_2 <- expanded_data %>%
    group_by(ENROLID, days) %>%
    mutate(
      exposed = if_else(
        str_detect(precipitant, precipitant_name) &
          days >= day_exposure_start & days <= day_exposure_end, 
        1, 0)
    ) %>%
    distinct(ENROLID, object, days, exposed) %>%
    ungroup()
  
  # Identify existing event columns in outcome dataset
  event_columns <- grep("^event_", names(outcome_dataset), value = TRUE)
  
  # Join expanded data with outcome dataset and mark events
  result <- expanded_data_2 %>%
    left_join(outcome_dataset, by = "ENROLID") %>%
    mutate(
       event = if_else(if_any(all_of(event_columns), ~ days == .), 1, 0, missing = 0) 
    ) %>%
    select(-all_of(event_columns)) |>  # Remove individual event columns
    arrange(ENROLID, days) %>%  # Ensure data is ordered correctly
    group_by(ENROLID) %>%  # Group by ENROLID to apply the logic per individual
    mutate(
       # Calculate washout period: 1 if exposed within the last 7 days
      washout = if_else(lag(exposed, 0) == 1 | lag(exposed, 1) == 1 | 
                        lag(exposed, 2) == 1 | lag(exposed, 3) == 1 |
                        lag(exposed, 4) == 1 | lag(exposed, 5) == 1 |
                        lag(exposed, 6) == 1, 1, 0)
    ) %>%
    ungroup() |> 
    # Reset washout to 0 if currently exposed
    mutate(washout = if_else(exposed == 1 & washout == 1, 0, washout)) |> 
    ungroup() |> 
    arrange(ENROLID, days)
  
  return(result)
}


# Function to get confidence intervals
get_confints <- function(model, parm) {
  try({
    # Attempt to get profile likelihood confidence intervals
    confints <- confint(model, parm = parm)
    confints_exp <- exp(confints)
    return(confints_exp)
  }, silent = TRUE)
  
 # If `confint` fails, proceed to manual calculation
  coef_parm <- coef(model)[parm]
  se_parm <- sqrt(vcov(model)[parm, parm])
  alpha <- 0.05
  z_value <- qnorm(1 - alpha / 2)
  confint_lower <- coef_parm - z_value * se_parm
  confint_upper <- coef_parm + z_value * se_parm
  confints_manual <- c(confint_lower, confint_upper)
  names(confints_manual) <- c("2.5 %", "97.5 %")
  confints_exp_manual <- exp(confints_manual)
  
  return(confints_exp_manual)
}

# Initialize the results tables
results_table <- data.frame()

#precipitant_vector <- "Levothyroxine Sodium"
# Loop through each precipitant
for (i in vector) {
  tryCatch({
    cat("Processing precipitant:", i, "\n") # Debug statement
    
    # Filter the data for the current precipitant
    temp_data <- data%>%
      filter(str_detect(str_trim(precipitant), i))
    
    if (nrow(data) == 0) {
      stop(paste("No data found for precipitant:", i))
    }
    

    # Apply the function to the data
    result <- expand_and_mark_exposure(temp_data, i, outcome_dataset)

    
    #Merge in NSAID data
    result_cov <- result |> 
      left_join(nsaid_data, by = c("ENROLID", "object", "days" )) |> 
      left_join(antiplatelet_data, by = c("ENROLID", "object", "days" ))  |> 
      left_join(other_anticoag_data, by = c("ENROLID", "object", "days" ))  |> 
      left_join(ssri_snri_data, by = c("ENROLID", "object", "days" ))  |> 
      left_join(giprotect_data, by = c("ENROLID", "object", "days")) |> 
      left_join(anticoagulant_data, by = c("ENROLID", "object", "days")) |> 
      mutate(
        nsaid_exposed = if_else(is.na(nsaid_exposed), 0, nsaid_exposed),
        antiplatelet_exposed = if_else(is.na(antiplatelet_exposed), 0, antiplatelet_exposed),
        other_anticoag_exposed = if_else(is.na(other_anticoag_exposed), 0, other_anticoag_exposed),
        ssri_snri_exposed = if_else(is.na(ssri_snri_exposed), 0, ssri_snri_exposed),
        giprotect_exposed = if_else(is.na(giprotect_exposed), 0, giprotect_exposed), 
        anticoagulant_exposed = if_else(is.na(anticoagulant_exposed), 0, anticoagulant_exposed)) 
    
    # Apply the function to create the binary indicator
    df <- result_cov %>%
      group_by(ENROLID) %>%
      arrange(ENROLID, days) %>%
      mutate(
        nsaid_30 = rollapplyr(nsaid_exposed, width = 30, FUN = sum, fill = NA, align = "right"),
        antiplatelet_30 = rollapplyr(antiplatelet_exposed, width = 30, FUN = sum, fill = NA, align = "right"), 
        other_anticoag_30 = rollapplyr(other_anticoag_exposed, width = 30, FUN = sum, fill = NA, align = "right"),
        ssri_snri_30 = rollapplyr(ssri_snri_exposed, width = 30, FUN = sum, fill = NA, align = "right"),
        giprotect_30 = rollapplyr(giprotect_exposed, width = 30, FUN = sum, fill = NA, align = "right")) %>%
      mutate(
        nsaid_30 = if_else(!is.na(nsaid_30) & nsaid_30 > 0, 1, 0),
        antiplatelet_30 = if_else(!is.na(antiplatelet_30) & antiplatelet_30 > 0, 1, 0), 
        other_anticoag_30 = if_else(!is.na(other_anticoag_30) & other_anticoag_30 > 0, 1, 0), 
        ssri_snri_30 = if_else(!is.na(ssri_snri_30) & ssri_snri_30 > 0, 1, 0),
        giprotect_30 = if_else(!is.na(giprotect_30) & giprotect_30 > 0, 1, 0)) %>%
      ungroup() |> 
      mutate(
        antiplatelet_30 = if_else(antiplatelet_exposed == 1, 1, antiplatelet_30),
        nsaid_30 = if_else(nsaid_exposed == 1, 1, nsaid_30),
        other_anticoag_30 = if_else(other_anticoag_exposed == 1, 1, other_anticoag_30),
        ssri_snri_30 = if_else(ssri_snri_exposed == 1, 1, ssri_snri_30),
        giprotect_30 = if_else(giprotect_exposed == 1, 1, giprotect_30)) |> 
      filter(anticoagulant_exposed == 0) # filter out observation days exposed to pravastatin (guidance from Zhou 2020)
    
    df <- df %>%
      mutate(offset = log(1))
    
    # Check for NA values in 'event' column before fitting the model
    if (any(is.na(df$event))) {
      stop("Missing values detected in 'event' column")
    }
    
    # Determine model formula based on current precipitant
    if (i %in% nsaids) {
      model_formula <- event ~ exposed + antiplatelet_30 + other_anticoag_30 + ssri_snri_30 + giprotect_30
    } else if (i %in% antiplatelet) {
      model_formula <- event ~ exposed + nsaid_30 + other_anticoag_30 + ssri_snri_30 + giprotect_30
    } else if (i %in% other_anticoag) {
      model_formula <- event ~ exposed + nsaid_30 + antiplatelet_30 + ssri_snri_30 + giprotect_30
    } else if (i %in% ssri_snri) {
      model_formula <- event ~ exposed + nsaid_30 + antiplatelet_30 + other_anticoag_30 + giprotect_30
    } else if (i %in% giprotect) {
      model_formula <- event ~ exposed + nsaid_30 + antiplatelet_30 + other_anticoag_30 + ssri_snri_30
    } else {
      model_formula <- event ~ exposed + nsaid_30 + antiplatelet_30 + other_anticoag_30 + ssri_snri_30 + giprotect_30
    }
    
    
    # Fit the conditional Poisson regression model
    df$ENROLID <- as.factor(df$ENROLID)
    
    # Exclude washout period and run the regression
    df_no_washout <- df %>% filter(washout == 0)

    model <- gnm(model_formula, eliminate = ENROLID, family = poisson(), data = df_no_washout)
    model_summary <- summary(model)
    
    coefs <- coef(model_summary)
    coefs_exp <- exp(coef(model))
    confints_exp <- get_confints(model, "exposed")

    
    combined_df2 <- data.frame(
      Estimate = coefs[1],
      IRR = coefs_exp[1],
      SE = summary(model)$coefficients[1, "Std. Error"],
      z_value = summary(model)$coefficients[1, "z value"],
      p_value = summary(model)$coefficients[1, "Pr(>|z|)"],
      `Lower 95%` = confints_exp[1],
      `Upper 95%` = confints_exp[2],
      drug = i
    )

    # Append to results table
    results_table <- bind_rows(results_table, combined_df2)
    
  }, error = function(e) {
    cat("ERROR with precipitant drug:", i, "\n", conditionMessage(e), "\n")
    #stop(paste("Error occurred with precipitant drug:", i))
  })
}
return(results_table)
}

pravastatin_results <- loop_function(pravastatin_cohort, pravastatin_vector, dataset_for_loop_outcome_pravastatin)

#generate number of precipitants with estimate; remove variance >10 as per Zhou paper: 
# Calculate variance from SE
pravastatin_results_filtered <- pravastatin_results %>%
  mutate(variance = SE^2) |> 
  filter(variance <= 10)

#save each of these datasets
write.xlsx(pravastatin_results, file = "pravastatin_shrinkage_results.xlsx", sheetName = "Raw", append = FALSE)
write.xlsx(pravastatin_results_filtered, file = "pravastatin_shrinkage_results.xlsx", sheetName = "Raw_Filtered", append = TRUE)


```

#Shrinkage

```{r}
#Shinkage: 
#Define the semi-Bayes shrinkage function
semi_bayes_shrinkage <- function(log_rr, se, prior_mean_log = 0, prior_var_log = 0.25) {
  # Calculate the precision (inverse of the variance)
  prior_precision = 1 / prior_var_log
  se_squared = se^2
  precision = 1 / se_squared
  
  # Calculate the posterior mean and variance
  post_precision = prior_precision + precision
  post_mean_log = (prior_mean_log * prior_precision + log_rr * precision) / post_precision
  post_var_log = 1 / post_precision
  
  # Calculate the posterior standard error
  post_se_log <- sqrt(post_var_log)
  
  # Calculate the shrunken log RR and confidence intervals
  shrunken_log_rr = post_mean_log
  lower_ci_log = post_mean_log - 1.96 * post_se_log
  upper_ci_log = post_mean_log + 1.96 * post_se_log
  
  return(data.frame(shrunken_log_rr, lower_ci_log, upper_ci_log, post_se_log))
}


# Apply the semi-Bayes shrinkage function to the regression results
apply_shrinkage_to_cohort <- function(data) {
  # Apply semi-Bayes shrinkage
  shrinkage_results <- data %>%
    mutate(
      shrinkage = map2(Estimate, SE, semi_bayes_shrinkage),  # Apply shrinkage
      shrunken_log_rr = map_dbl(shrinkage, "shrunken_log_rr"),
      lower_ci_log = map_dbl(shrinkage, "lower_ci_log"),
      upper_ci_log = map_dbl(shrinkage, "upper_ci_log"),
      post_se_log = map_dbl(shrinkage, "post_se_log"),  # Extract posterior SE
      shrunken_irr = exp(shrunken_log_rr),
      lower_ci = exp(lower_ci_log),
      upper_ci = exp(upper_ci_log)
    ) %>%
    select(-shrinkage)
  
  # Filter for statistically significant results
  significant_results <- shrinkage_results %>%
    filter(lower_ci > 1 | upper_ci < 1)
  
  return(list(all_results = shrinkage_results, significant_results = significant_results))
}

# Apply shrinkage to each pravastatin
pravastatin_shrinkage <- apply_shrinkage_to_cohort(pravastatin_results)

# Extract results for each
pravastatin_shrinkage_results <- pravastatin_shrinkage$all_results
pravastatin_significant_results <- pravastatin_shrinkage$significant_results


# Export both tables to separate sheets in the same Excel file
write.xlsx(pravastatin_shrinkage_results, file = "pravastatin_shrinkage_results.xlsx", sheetName = "Shrunk Results", append = TRUE)
write.xlsx(pravastatin_significant_results, file = "pravastatin_shrinkage_results.xlsx", sheetName = "Significant Shrunk Results", append = TRUE)
```
